---
title: "Modulo_2"
author: "Fernando Alvarado"
date: "2025-04-15"
output: html_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

```

## ğŸ“‚ Lectura de datos Excel `.xlsx` con `readxl` y exploraciÃ³n rÃ¡pida con `skimr`

- Para leer archivos Excel (.xls y .xlsx) usamos el paquete `readxl`.

- La funciÃ³n principal es: `read_xlsx("ruta", sheet = "nombre_hoja")`.

- El archivo debe estar ubicado en la misma carpeta del script o se debe indicar su ruta.

- Para explorar rÃ¡pidamente un dataframe, `skimr::skim()` genera estadÃ­sticas resumen por variable.

- Esta salida se puede guardar y analizar como un dataframe de metadatos.




```{r message=FALSE, warning=FALSE}


library(readxl)   # Leer archivos de Excel
library(dplyr)    # ManipulaciÃ³n de datos
library(ggplot2)  # VisualizaciÃ³n
library(lubridate) # Manejo de fechas
library(skimr)    # ExploraciÃ³n estructurada de dataframes

# ------------------------------------------------------
# ğŸ“¥ Lectura del archivo Excel con la hoja "Ventas"

setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
datos_ventas <- read_xlsx("./datos_simulados.xlsx")
datos_ventas |> head()

# ğŸ“‹ RevisiÃ³n de la estructura general del dataframe
str(datos_ventas)

# ğŸ“Š ExploraciÃ³n detallada con skim()
skim(datos_ventas)



# ğŸ” Acceder a los tipos de variable que detectÃ³ skimr
mi_metadata$skim_type

```



## ğŸ“… Manejo de fechas con `lubridate` y creaciÃ³n de variables temporales


### ğŸ“ Resumen

- Muchas veces las fechas vienen mal codificadas como texto (`string`).  
  Debemos convertirlas a formato fecha usando `as.Date()`.

- El paquete `{lubridate}` permite extraer partes Ãºtiles de las fechas:
  - DÃ­a (`day()`), mes (`month()`), aÃ±o (`year()`), dÃ­a de la semana (`wday()`), etc.

- Una vez que las fechas estÃ¡n en formato `Date`, podemos:
  - Calcular el tiempo entre eventos (por ejemplo: entrega, salida, procesamiento).
  - Crear columnas nuevas con caracterÃ­sticas como el mes o el dÃ­a de la semana.

- Las operaciones entre fechas, como restas, devuelven diferencias en **dÃ­as** por defecto.

âš ï¸ **Importante:** AsegÃºrate de que **todas las fechas estÃ©n en el mismo formato** antes de realizar operaciones con ellas.

---

## ğŸ“… Limpieza de columna `Fecha Venta` y creaciÃ³n de variables de tiempo


```{r message=FALSE, warning=FALSE}

# ğŸ“¦ Carga de librerÃ­as
library(readxl)
library(dplyr)
library(lubridate)

# ğŸ“¥ Lectura del archivo desde hoja "Ventas"
setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
datos_ventas <- read_xlsx("./datos_simulados.xlsx")

# ğŸ”§ Limpieza de columna Fecha_venta
datos_ventas <- datos_ventas %>%
  mutate(Fecha_venta = as.Date(Fecha_venta)) %>%  # convierte de datetime a date
  mutate(
    MesVenta   = month(Fecha_venta),
    DiaVenta   = day(Fecha_venta),
    DiaSemana  = wday(Fecha_venta, label = TRUE, abbr = FALSE)  # Lunes, Martes, etc.
  )

# ğŸ‘ï¸ VisualizaciÃ³n rÃ¡pida
head(datos_ventas)
```



## ğŸ“Š Lectura de archivos `.xls` y anÃ¡lisis rÃ¡pido con `inspectdf`



- Los archivos `.xls` (formato de Excel antiguo) tambiÃ©n se pueden leer con la funciÃ³n `readxl::read_xls()`.

- La librerÃ­a `{inspectdf}` permite explorar rÃ¡pidamente un `data.frame` mediante visualizaciones automÃ¡ticas y resÃºmenes estadÃ­sticos Ãºtiles.

#### ğŸ” Funciones clave del paquete `{inspectdf}`:

- `inspect_na()`: analiza la cantidad y proporciÃ³n de valores faltantes (`NA`) por columna.
- `inspect_cat()`: inspecciona columnas categÃ³ricas y muestra la distribuciÃ³n de sus valores.
- `inspect_cor()`: muestra la correlaciÃ³n entre variables numÃ©ricas.
- `inspect_types()`: indica cuÃ¡ntas variables hay de cada tipo de dato (numÃ©rico, lÃ³gico, carÃ¡cter, etc.).
- `inspect_num()`: genera estadÃ­sticas bÃ¡sicas para variables numÃ©ricas (media, mediana, desviaciÃ³n estÃ¡ndar, etc.).
- `show_plot()`: genera automÃ¡ticamente una grÃ¡fica para cualquier resultado obtenido con las funciones `inspect_*`.

ğŸ’¡ *Tip*: Todas las funciones `inspect_*()` devuelven tibbles, por lo que tambiÃ©n puedes manipular sus resultados con `dplyr`.

---


```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ Carga de librerÃ­as
library(readxl)
library(dplyr)
library(inspectdf)

# ğŸ“¥ Lectura del archivo .xls (Superstore clÃ¡sico)
setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
data_superstore <- read_xlsx("./datos_simulados.xlsx") # <- CÃ¡mbialo si tienes otro archivo .xls real
head(data_superstore)

# ------------------------------------------------------
# ğŸ§ª ExploraciÃ³n del dataframe con inspectdf

# AnÃ¡lisis de valores faltantes
inspect_na(data_superstore)
inspect_na(data_superstore) |> show_plot()

# AnÃ¡lisis de variables categÃ³ricas
inspect_cat(data_superstore)
inspect_cat(data_superstore) |> show_plot()

# CorrelaciÃ³n entre variables numÃ©ricas
inspect_cor(data_superstore) |> show_plot()

# Tipos de variables (numÃ©ricas, categÃ³ricas, etc.)
inspect_types(data_superstore)
inspect_types(data_superstore) |> show_plot()

# Resumen de variables numÃ©ricas
inspect_num(data_superstore)
inspect_num(data_superstore) |> show_plot()
```



## ğŸ—ºï¸ VisualizaciÃ³n geogrÃ¡fica con `maps` + `ggplot2` + `dplyr`


### ğŸ“ Resumen

- La librerÃ­a `{maps}` permite acceder a mapas geogrÃ¡ficos predefinidos: estados de EE.UU., paÃ­ses, condados, etc.
- Combinada con `{ggplot2}`, es posible crear mapas temÃ¡ticos que representen una variable cuantitativa (por ejemplo, ganancias por estado).
- En este ejemplo se usa la suma de `Profit` por estado a partir del dataset `data_superstore`.

---

#### ğŸ” Flujo general para graficar un mapa temÃ¡tico:

1. **Agrupar datos por estado** y calcular la ganancia total (`Profit`) con `group_by()` y `summarise()`.
2. **Homogeneizar nombres de estados**, convirtiÃ©ndolos a minÃºsculas para que coincidan con los del objeto `map_data("state")`.
3. **Unir los datos** de ganancias con el mapa base utilizando `left_join()`, emparejando por nombre del estado.
4. **Calcular las coordenadas centrales** de cada estado para agregar etiquetas (`geom_label_repel()`).
5. **Graficar** el mapa con `geom_polygon()` para las Ã¡reas y `geom_label_repel()` para mostrar nombres o datos sobre los estados.

ğŸ’¡ *Tip:* AsegÃºrate que las variables estÃ©n bien alineadas (nombres y formatos) antes de hacer el `join`, o la grÃ¡fica podrÃ­a quedar vacÃ­a o desfasada.


# Bases de datos mÃ¡s estructuradas

```{r}
library(DBI)
library(dbplyr)
library(RSQLite)
library(Lahman)
```

+ SQLite es un sistema de administraciÃ³n de bases de datos relacionales (RDBMS, Relational Database Management System)

+ Es ligero, serverless (sin servidor), self-contained (autÃ³nomo) e integrado (embedded)

Se utiliza para el almacenamiento local de datos en aplicaciones, prototipos y proyectos pequeÃ±os o medianos

## Ligero (y rÃ¡pido):

+ SQLite estÃ¡ diseÃ±ado para ser ligero y eficiente, lo que lo hace ideal para aplicaciones con trÃ¡fico bajo o moderado, o para su uso en sistemas integrados.

+ Funciona bien para aplicaciones pequeÃ±as, pero puede no ser adecuado para sistemas de alta concurrencia o a gran escala.

## Serverless:

+ A diferencia de bases de datos tradicionales como MySQL o PostgreSQL, SQLite no requiere un proceso de servidor separado para funcionar.

+ La base de datos se almacena en un solo archivo en el disco, y la biblioteca lee y escribe directamente en ese archivo.

## Self-Contained:

+ Es un sistema autÃ³nomo, lo que significa que no tiene dependencias externas. Todo el motor de la base de datos estÃ¡ contenido dentro de una sola biblioteca.

## ConfiguraciÃ³n cero

+ No requiere configuraciÃ³n ni administraciÃ³n. No es necesario instalar un servidor, configurar usuarios o administrarar permisos.

## Base de datos en un solo archivo:

+ Toda la base de datos (tablas, Ã­ndices y datos) se almacena en un solo archivo en el disco (por ejemplo, mibasededatos.db). Por lo tanto es muy fÃ¡cil copiar, mover o compartir la base de datos.

## Adicionales:

+ SQLite es multiplataforma y funciona en varios sistemas operativos, incluyendo Windows, macOS, Linux, iOS y Android.

+ Admite propiedades ACID (Atomicidad, Consistencia, Aislamiento, Durabilidad), lo que garantiza transacciones confiables incluso en caso de fallos del sistema.

+ Es open-source y se publica bajo dominio pÃºblico, lo que significa que es gratis para cualquier uso sin restricciones de licencia.

# Empecenmos...

+ Una de las formas mÃ¡s fÃ¡ciles es con DBI utilizando la funciÃ³n `dbGetQuery()` 

+ Se hace copy/paste de cÃ³digo SQL en la funciÃ³n de R como un string entre comillas

+ Esta forma se conoce como pass through SQL code



## ğŸ—ƒï¸ Bases de datos SQLite en R con `DBI` y `RSQLite`

```{r message=FALSE, warning=FALSE}
### ğŸ“ Resumen

# - `DBI::dbConnect()` crea una conexiÃ³n a una base de datos SQLite.
# - `dbListTables()` muestra las tablas disponibles.
# - `dbWriteTable()` permite escribir un dataframe en la base de datos (crear o sobrescribir tablas).
# - `dbGetQuery()` ejecuta consultas SQL directamente sobre la base de datos y devuelve un dataframe.
# - Se puede usar SQL clÃ¡sico para hacer SELECT, WHERE, LIKE, GROUP BY, etc.
# - Usando `append = TRUE` en `dbWriteTable()` se pueden insertar mÃºltiples dataframes como si fueran filas nuevas.

# ------------------------------------------------------
# ğŸ“¦ Cargar paquetes y conectar base de datos
library(DBI)
library(RSQLite)
library(dplyr)

# Crear conexiÃ³n a la base de datos
setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
conn <- dbConnect(SQLite(), "./CarsDB.db")

# Listar tablas existentes
dbListTables(conn)

# ------------------------------------------------------
# ğŸ› ï¸ Preparar los datos: mtcars con columna de nombres de autos
datos <- mtcars
datos$car_names <- rownames(datos)
rownames(datos) <- NULL
head(datos)

# Escribir tabla "cars_data"
dbWriteTable(conn, "cars_data", datos, overwrite = TRUE)
dbListTables(conn)

# ------------------------------------------------------
# ğŸ” Consultas SQL a la tabla

# Todos los registros
dbGetQuery(conn, "SELECT * FROM cars_data") |> head()

# Solo los primeros 10
dbGetQuery(conn, "SELECT * FROM cars_data LIMIT 10") |> head()

# Autos con 8 cilindros
dbGetQuery(conn,"SELECT car_names, hp, cyl FROM cars_data WHERE cyl = 8")|> head()

# Autos que empiezan con "M" y tienen 6 u 8 cilindros
dbGetQuery(conn,"SELECT car_names, hp, cyl FROM cars_data 
                 WHERE car_names LIKE 'M%' AND cyl IN (6,8)")  |> head()

# Promedio de hp y mpg por cilindros
dbGetQuery(conn,"SELECT cyl, AVG(hp) AS average_hp, AVG(mpg) AS average_mpg 
                 FROM cars_data 
                 GROUP BY cyl 
                 ORDER BY average_hp") |> head()

# Guardar resumen en un dataframe de R
resumen <- dbGetQuery(conn,"SELECT cyl, AVG(hp) AS average_hp 
                            FROM cars_data 
                            GROUP BY cyl 
                            ORDER BY average_hp") |> head()

# Ver clase del objeto obtenido

# ------------------------------------------------------
# ğŸ§© Escribir mÃºltiples dataframes desde lista

# Crear dos dataframes con autos y fabricantes
autos <- c('Camaro', 'California', 'Mustang', 'Explorer')
fabricante <- c('Chevrolet','Ferrari','Ford','Ford')
df1 <- data.frame(autos, fabricante)

autos <- c('Corolla', 'Lancer', 'Sportage', 'XE')
fabricante <- c('Toyota','Mitsubishi','Kia','Jaguar')
df2 <- data.frame(autos, fabricante)

# Lista de dataframes
lista_dfs <- list(df1, df2)

# Insertar todos en la tabla "otros_autos"
for(k in 1:length(lista_dfs)){
  dbWriteTable(conn, "otros_autos", lista_dfs[[k]], append = TRUE) 
}

# Verificar tablas y contenido
dbListTables(conn) |> head()
dbGetQuery(conn, "SELECT * FROM otros_autos") |> head()
```


### ğŸ“ Resumen general: uso de SQLite y consultas SQL en R

- **SQLite** es un sistema de bases de datos relacional que se caracteriza por ser:
  - Ligero y rÃ¡pido.
  - Serverless (no necesita servidor).
  - Self-contained (todo estÃ¡ en una sola biblioteca).
  - De configuraciÃ³n cero.
  - Basado en un solo archivo `.db`.
  - Multiplataforma y de cÃ³digo abierto.
  - Compatible con transacciones ACID (seguras y confiables).

- Es ideal para prototipos, aplicaciones mÃ³viles y proyectos con almacenamiento local.

---

## ğŸ”— ConexiÃ³n a SQLite en R

Para conectar una base de datos SQLite desde R, usamos:



```{r message=FALSE, warning=FALSE}

library(DBI)
library(RSQLite)

setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
conn <- dbConnect(SQLite(), "./CarsDB.db")

# Definimos nuestros parÃ¡metros
millas <- 18
cilindros <- 6

# Consulta con parÃ¡metros definidos en R
mi_df_query <- dbGetQuery(conn,
  'SELECT car_names, mpg, cyl FROM cars_data WHERE mpg >= ? AND cyl >= ?',
  params = c(millas, cilindros))

mi_df_query

# ------------------------------------------------------
# ğŸ§¹ Cerrar conexiÃ³n
dbDisconnect(conn)

# ------------------------------------------------------
# ğŸ“¦ Trabajar con bases de datos usando dbplyr
library(dbplyr)

# Base de datos SQLite con datos de bÃ©isbol (Lahman)
lahman_s <- lahman_sqlite()
bateo <- tbl(lahman_s, "Batting")

# Ver clase del objeto (es un objeto remoto)
class(bateo)

# Ver consulta SQL generada
bateo %>% show_query()

# Filtrar por un jugador especÃ­fico
bateo %>% filter(playerID == "mcguide01")

# Mostrar la query resultante de esa operaciÃ³n
bateo %>%
  filter(playerID == "mcguide01") %>%
  show_query()

# Encadenar mÃ¡s operaciones (filtrar + seleccionar)
bateo %>%
  filter(playerID == "mcguide01") %>%
  select(yearID, R) %>%
  show_query()

# Agregar columna condicional con mutate()
bateo %>%
  filter(playerID == "mcguide01") %>%
  mutate(era = if_else(yearID <= 1888, "vieja era", "nueva era")) %>%
  select(playerID, yearID, era, teamID) %>%
  show_query()

```



## ğŸ“† De Excel y sus infiernos con las fechas: `excel_numeric_to_date()` y `convert_to_date()`


### ğŸ“ Resumen

- Excel guarda las fechas como **nÃºmeros secuenciales**. Por ejemplo, el valor `41103` representa la fecha `"2012-07-03"`.
- Esto puede generar confusiÃ³n al importar datos: ves nÃºmeros como `42000` en lugar de fechas legibles.
- La funciÃ³n `excel_numeric_to_date()` convierte esos nÃºmeros en objetos de clase `Date` en R.
- Si activas `include_time = TRUE`, tambiÃ©n recuperas la hora exacta (en formato `POSIXlt`), Ãºtil si hay decimales.
- Puedes especificar el **sistema de fechas** (por ejemplo, el usado por Excel en Mac antes de 2011), lo que garantiza una conversiÃ³n correcta.

---

### ğŸ“¦ Bonus

- Las funciones `convert_to_date()` y `convert_to_datetime()` son mÃ¡s **robustas** que `excel_numeric_to_date()`.
- Son capaces de manejar **mezclas de nÃºmeros y strings** de fechas en una misma columna.
- Resultan ideales cuando los formatos son **inconsistentes** entre columnas o archivos Excel diferentes.



```{r message=FALSE, warning=FALSE}


# ------------------------------------------------------
# ğŸ“¦ LibrerÃ­as necesarias
library(readxl)
library(lubridate)
library(vroom)         # convert_to_date() viene de este paquete
library(forcats)       # para factores ordenados


# ------------------------------------------------------
# ğŸ“… ConversiÃ³n desde cÃ³digo numÃ©rico de Excel
#excel_numeric_to_date(41103)
#excel_numeric_to_date(41103.01)  # Ignora decimales por defecto
#excel_numeric_to_date(41103.01, include_time = TRUE)  # Convierte a POSIXlt (incluye hora)
#excel_numeric_to_date(41103.01, date_system = "mac pre-2011")

# ------------------------------------------------------
# ğŸ§  Funciones mÃ¡s robustas con entradas mixtas
#convert_to_date(c("2020-02-29", "40000.1"))
#convert_to_date(c("2020-02-29", "40000.1", "26-04-2021"))
#convert_to_date(c("2020-02-29", "40000.1", "04-26-2021"))
#convert_to_date(c("2020-02-29", "40000.1", "2021/04/26"))



```

## **Clase 3, empezamos a ver limpieza de datos**



## ğŸ§¼ IntroducciÃ³n a limpieza de datos con `janitor` y verificaciÃ³n de estructuras

### ğŸ§¼ Resumen: Limpieza de datos al importar archivos

- Al importar archivos `.csv`, `.xls`, `.xlsx` o conectarse a bases de datos, los datos pueden venir **mal formateados** o con estructuras inconsistentes.
- La **limpieza de datos** es una de las etapas mÃ¡s **tardadas y crÃ­ticas** del pipeline de ciencia de datos.

---

### ğŸ“¦ Paquetes Ãºtiles para limpieza

- `janitor::clean_names()`: Limpia nombres de columnas eliminando acentos, espacios, caracteres especiales, y los convierte a **snake_case** en minÃºsculas.
- `compare_df_cols()` y `compare_df_cols_same()` (de `{janitor}`): Comparan estructuras entre dataframes, muy Ãºtiles antes de usar `bind_rows()` o `rbind()`.
- `janitor::tabyl()`: Genera **tablas de frecuencia** claras y bien presentadas, ideal para columnas categÃ³ricas. Es una mejora sobre la funciÃ³n base `table()`.

ğŸ’¡ *Tip:* Usar estos paquetes desde el inicio ahorra tiempo y evita errores en anÃ¡lisis posteriores.



```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ Cargar librerÃ­as
library(readxl)
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate)
library(janitor)

# ------------------------------------------------------
# ğŸ“¥ Cargar archivo Excel
setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
datos_ventas <- read_xlsx("./VentasNum2024.xlsx")
head(datos_ventas)
names(datos_ventas)

# âœ¨ Limpiar nombres de columnas
datos_ventas <- datos_ventas |> clean_names()
names(datos_ventas)

# ------------------------------------------------------
# ğŸ§ª VerificaciÃ³n de estructura entre dataframes

# SimulaciÃ³n de dataframes
df1 <- data.frame(a = 1:2, b = c("grande", "pequeÃ±o"))
df2 <- data.frame(a = 10:12, b = c("mediano", "pequeÃ±o", "grande"), c = 0,
                  stringsAsFactors = TRUE)
df3 <- df1 |> mutate(b = as.character(b))

# Ver dataframes
df1
df2
df3

# Comparar estructuras
compare_df_cols(df1, df2, df3)

# ComparaciÃ³n con detalles de incompatibilidad
compare_df_cols(df1, df2, df3, return = "mismatch")

# ComparaciÃ³n para apilar por filas
compare_df_cols(df1, df2, df3, return = "mismatch", bind_method = "rbind")

# Â¿Se pueden combinar sin problemas?
compare_df_cols_same(df1, df3)
compare_df_cols_same(df2, df3)

# ------------------------------------------------------
# ğŸ“Š Tablas cruzadas y limpieza visual

# Tabla cruzada simple
mtcars %>% tabyl(gear, cyl)

# Tabla cruzada por 3 variables (am = transmisiÃ³n automÃ¡tica)
mtcars %>% tabyl(gear, cyl, am)

# Adornar tablas con totales y porcentajes
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col") %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns() %>%
  adorn_title()
```





## ğŸ” DetecciÃ³n de duplicados y relaciones uno-a-uno con `{janitor}`



- `get_dupes()`: Busca filas duplicadas dentro de un dataframe, ya sea considerando **todas las columnas** o solo un subconjunto.

#### Â¿Para quÃ© sirve?
- Verificar si una columna puede funcionar como **identificador Ãºnico**.
- Detectar registros **repetidos parcialmente** (por ejemplo, mismos nombres pero con datos diferentes).

---

- `get_one_to_one()`: EvalÃºa si existe una relaciÃ³n **uno a uno** entre dos columnas (o mÃ¡s).

#### Â¿QuÃ© permite verificar?
- Si puedes **predecir completamente una columna a partir de otra**.
- Si hay **redundancia** en las variables.
- Es Ãºtil para validar **llaves candidatas** o relaciones entre claves primarias y forÃ¡neas.

ğŸ’¡ *Tip:* Estas funciones provienen del paquete `{janitor}` y son especialmente Ãºtiles en etapas tempranas del anÃ¡lisis de datos.



```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ Cargar librerÃ­as
library(dplyr)
library(janitor)
library(readr)

# ------------------------------------------------------
# ğŸ§ª DetecciÃ³n de duplicados

# Todos los renglones de mtcars son Ãºnicos
get_dupes(dat = mtcars)

# Â¿Hay duplicados en columnas especÃ­ficas?
get_dupes(dat = mtcars, wt, cyl)

# Verificar si una columna (como id_venta) es un ID Ãºnico
setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
datos_ventas <- readxl::read_xlsx("./VentasNum2024.xlsx") |> clean_names()
get_dupes(dat = datos_ventas, id_venta)

# ------------------------------------------------------
# ğŸ” Verificar relaciones uno-a-uno

# Usamos dataset starwars incluido en dplyr
datos <- dplyr::starwars

# Primeros 10 renglones: Â¿hay columnas con relaciÃ³n 1 a 1?
datos[1:10, ] %>% get_one_to_one()

# MÃ¡s restringido: solo los primeros 5
datos[1:5, ] %>% get_one_to_one()

# Inspeccionar visualmente algunas columnas
datos[1:5, ] %>% dplyr::select(name, height, mass, skin_color)
datos[1:5, ] %>% dplyr::select(birth_year, films)

# ------------------------------------------------------
# ğŸ“¦ Dataset real: Superstore

data_superstore <- read_csv("./Sample - Superstore.csv")

# Buscar relaciones uno-a-uno entre columnas
data_superstore |> get_one_to_one()

# Ejemplo especÃ­fico: Â¿Customer ID predice Customer Name?
data_superstore |> dplyr::select(`Customer ID`, `Customer Name`)
```



## âŒ Manejo de NAs (valores faltantes) con `{visdat}` y `{naniar}`


- El manejo adecuado de valores faltantes (`NA`) es una etapa crÃ­tica en la limpieza de datos.
- Eliminar filas o columnas con `NA` de forma directa puede llevar a la pÃ©rdida de informaciÃ³n importante o sesgos en el anÃ¡lisis.

---

### ğŸ“¦ Paquetes Ãºtiles

#### `{visdat}`
- Permite visualizar tipos de datos y presencia de valores faltantes:
  - `vis_dat()`: muestra el tipo de cada variable y sus valores.
  - `vis_miss()`: muestra un mapa de NAs por observaciÃ³n.

#### `{naniar}`
- Especializado en la exploraciÃ³n y anÃ¡lisis de datos faltantes:
  - `gg_miss_var()`: grafica la proporciÃ³n de `NA` por variable.
  - `add_prop_miss()`: aÃ±ade una columna con el porcentaje de `NA` por fila.
  - `miss_var_summary()`: genera un resumen tabular con el total y proporciÃ³n de `NA` por columna.
  - `geom_miss_point()`: visualizaciÃ³n de puntos perdidos en variables numÃ©ricas.
  - `miss_var_run()`: analiza rachas (runs) de valores faltantes consecutivos.
  - `miss_var_span()`: evalÃºa la presencia de `NA` en bloques de observaciones.
  - `miss_var_table()`: muestra cuÃ¡ntas columnas tienen una cierta cantidad de valores faltantes.

ğŸ’¡ *Tip:* Antes de imputar o eliminar datos, analiza con visualizaciones y resÃºmenes dÃ³nde y cÃ³mo se presentan los `NA`.


```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ Cargar librerÃ­as
library(dplyr)
library(visdat)
library(naniar)
library(ggplot2)

# ------------------------------------------------------
# ğŸ§ª Ejemplo bÃ¡sico
mi_dataframe <- data.frame(v1 = c(1, NA, 3),
                           v2 = c(NA, NA, NA),
                           v3 = c("a", NA, "b"))
mi_dataframe

# âŒ Remover filas y columnas vacÃ­as (demasiado drÃ¡stico)
remove_empty(mi_dataframe, c("rows", "cols"))

# ------------------------------------------------------
# ğŸ“Š Dataset de ejemplo: airquality (base de R)
datos <- airquality
head(datos)

# VisualizaciÃ³n general de los tipos de datos y NAs
datos %>% vis_dat()

# VisualizaciÃ³n centrada sÃ³lo en los NAs
datos %>% vis_miss()

# GrÃ¡fico de proporciÃ³n de NAs por variable
datos %>% gg_miss_var()

# Facet por mes
datos %>% gg_miss_var(facet = Month)

# Agregar columna con proporciÃ³n de NAs por fila
datos %>% add_prop_miss() %>% head(15)

# Resumen tabular por columna
datos %>% miss_var_summary()

# Tabla resumen de cuÃ¡ntas variables tienen cuÃ¡ntos NAs
datos %>% miss_var_table()

# GrÃ¡fico de dispersiÃ³n con NAs visualizados
datos %>%
  ggplot(aes(x = Solar.R, y = Ozone)) +
  geom_miss_point()

# Con facet por mes
datos %>%
  ggplot(aes(x = Solar.R, y = Ozone)) +
  geom_miss_point() +
  facet_wrap(~Month)

# AnÃ¡lisis de rachas de NAs en la variable Ozone
miss_var_run(datos, Ozone)

# AnÃ¡lisis por bloques de 20 filas
miss_var_span(datos, Ozone, span_every = 20)

# NAs en Ozone agrupados por mes
datos %>%
  group_by(Month) %>%
  miss_var_summary() %>%
  filter(variable == "Ozone")
```


## ğŸ§© ImputaciÃ³n y anÃ¡lisis avanzado de valores faltantes con `naniar`, `simputation` y `mice`

### ğŸ“ Resumen: Rastrear y rellenar valores faltantes

- Las funciones `bind_shadow()` y `as_shadow()` (del paquete `{naniar}`) permiten **rastrear valores faltantes** creando columnas auxiliares con sufijos `_NA`.

#### Â¿Para quÃ© sirven estas columnas extras?
- Analizar **cuÃ¡ndo y dÃ³nde** faltan datos.
- Estudiar **relaciones entre los NAs y otras variables** del dataset.

---

### ğŸ“¦ ImputaciÃ³n de datos faltantes

El paquete `{simputation}` ofrece funciones prÃ¡cticas para **rellenar (imputar)** valores perdidos:

- `impute_lm()`: usa regresiÃ³n lineal para imputar valores.
- `impute_median()`: imputaciÃ³n basada en la **mediana**, Ãºtil para variables con outliers o agrupaciones.
- `impute_cart()`: utiliza Ã¡rboles de decisiÃ³n (**CART**) para imputar valores segÃºn relaciones no lineales.

---

### ğŸ§  ImputaciÃ³n mÃºltiple avanzada

- El paquete `{mice}` permite realizar **imputaciÃ³n mÃºltiple**, tÃ©cnica mÃ¡s robusta para anÃ¡lisis serios.
- Aunque en este contexto solo usamos su funciÃ³n para **visualizar patrones de datos faltantes**, es Ãºtil saber que `{mice}` tambiÃ©n puede generar mÃºltiples datasets imputados de forma coherente.

ğŸ’¡ *Tip:* Rastrear los `NA` antes de imputar ayuda a detectar sesgos estructurales y evitar errores graves.


```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ Cargar librerÃ­as
library(dplyr)
library(janitor)
library(naniar)
library(simputation)
library(ggplot2)
library(mice)

# ------------------------------------------------------
# ğŸ“Š Dataset: airquality (con NAs en Ozone y Solar.R)
datos <- airquality

# Crear tabla sombra: marca dÃ³nde hay NAs
datos |> as_shadow() |> head(15)
datos |> bind_shadow() |> head(15)
datos |> bind_shadow() |> glimpse() |> head(15)

# EstadÃ­sticas por presencia/ausencia de NAs en Ozone
datos %>% bind_shadow() %>%
  group_by(Ozone_NA) %>%
  summarise_at(.vars = "Solar.R",
               .funs = c("mean", "sd", "var", "min", "max"),
               na.rm = TRUE) |> head()

# VisualizaciÃ³n de densidad separada por Ozone_NA
datos %>% bind_shadow() %>%
  ggplot(aes(x = Temp, colour = Ozone_NA)) + 
  geom_density() 

datos %>% bind_shadow() %>%
  ggplot(aes(x = Solar.R, colour = Ozone_NA)) + 
  geom_density()

# ------------------------------------------------------
# ğŸ“¥ ImputaciÃ³n usando regresiÃ³n lineal
datos_imp_reglin <- impute_lm(datos, Ozone ~ Temp + Wind)
head(datos_imp_reglin, 15)
datos_imp_reglin |> miss_var_summary() |> head()

# VisualizaciÃ³n post-imputaciÃ³n
datos %>%
  bind_shadow() %>%
  as.data.frame() %>%
  impute_lm(Ozone ~ Temp + Wind) %>%
  ggplot(aes(x = Temp, y = Ozone, colour = Ozone_NA)) +
  geom_point() 
datos %>%
  bind_shadow() %>%
  as.data.frame() %>%
  impute_lm(Ozone ~ Temp + Wind) %>%
  ggplot(aes(x = Wind, y = Ozone, colour = Ozone_NA)) +
  geom_point()

# ------------------------------------------------------
# ğŸ§  ImputaciÃ³n avanzada considerando Solar.R tambiÃ©n
datos_imp_reglin2 <- impute_lm(datos, Ozone ~ Solar.R + Temp + Wind)
head(datos_imp_reglin2)
datos_imp_reglin2 |> miss_var_summary()

# Rellenar los NA restantes con mediana por mes
datos_imp_reglin_med <- impute_median(datos_imp_reglin2, Ozone ~ Month)
head(datos_imp_reglin_med, 15)
datos_imp_reglin_med |> miss_var_summary()

# ------------------------------------------------------
# ğŸŒ² ImputaciÃ³n con Ã¡rboles de decisiÃ³n (CART)
datos_imp_arbol <- impute_cart(datos, Ozone ~ .)
head(datos_imp_arbol)
datos_imp_arbol |> miss_var_summary()

# VisualizaciÃ³n: imputaciÃ³n usando Ã¡rbol
datos %>%
  bind_shadow() %>%
  as.data.frame() %>%
  impute_cart(Ozone ~ .) %>%
  ggplot(aes(x = Wind, y = Ozone, colour = Ozone_NA)) +
  geom_point()

# Visualizar impacto sobre otra variable faltante (Solar.R)
datos %>%
  bind_shadow() %>%
  as.data.frame() %>%
  impute_cart(Ozone ~ .) %>%
  ggplot(aes(x = Temp, y = Ozone, colour = Solar.R_NA)) +
  geom_point()

# ------------------------------------------------------
# ğŸ“Š AnÃ¡lisis de patrones de NAs
datos |> md.pattern()
```



## ğŸ§  DetecciÃ³n de columnas sin informaciÃ³n y predicciÃ³n de valores faltantes

### ğŸ“ Resumen: DetecciÃ³n avanzada de problemas en datos

- A veces los datasets no solo contienen `NA`, sino tambiÃ©n columnas problemÃ¡ticas como:
  - **Constantes**: variables que no cambian entre observaciones (sin informaciÃ³n Ãºtil).
  - **Mal importadas**: cuando los encabezados estÃ¡n desplazados y aparecen como filas.

---

### ğŸ“¦ Funciones Ãºtiles del paquete `{janitor}`

- `remove_constant()`: elimina columnas que tienen el mismo valor en todos los registros.
- `row_to_names()`: transforma una fila (usualmente la primera) en nombres de columna, Ãºtil cuando la cabecera del archivo no fue leÃ­da correctamente.

---

### ğŸ“Š AnÃ¡lisis con Ã¡rboles de decisiÃ³n

TambiÃ©n podemos usar **Ã¡rboles de decisiÃ³n** con el paquete `{rpart}` para:

- Predecir **quÃ© variables explican la presencia de valores faltantes**.
- Identificar patrones en los `NA` segÃºn otras variables.
- Visualizar las **caracterÃ­sticas de los datos asociadas a registros incompletos**, lo que puede ayudar a definir estrategias de imputaciÃ³n o exclusiÃ³n.

ğŸ’¡ *Tip:* Este tipo de anÃ¡lisis es muy Ãºtil en etapas exploratorias cuando los `NA` no parecen aleatorios.


```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ Cargar librerÃ­as
library(dplyr)
library(janitor)
library(naniar)
library(rpart)
library(rpart.plot)

# ------------------------------------------------------
# ğŸ“ˆ Ãrbol de decisiÃ³n para entender quÃ© variables predicen los NAs
datos <- airquality

datos %>%
  add_prop_miss() %>%
  rpart(prop_miss_all ~ ., data = .) %>%
  prp(type = 4, extra = 101, prefix = "Prop. Miss = ", cex = 0.7)

# ------------------------------------------------------
# ğŸ§ª DetecciÃ³n de columnas sin variabilidad

mi_dataframe <- data.frame(
  estudiantes = c("Felipe", "VerÃ³nica", "Alina"),
  calificaciones = 8:10,
  curso = "MatemÃ¡ticas"
)

# curso es constante
mi_dataframe |> remove_constant()

# ------------------------------------------------------
# ğŸ“‚ ReparaciÃ³n de archivos mal estructurados (encabezados desfasados)

df_que_me_pasaron <- data.frame(
  X_1 = c(NA, "ID", 1:3),
  X_2 = c(NA, "Value", 4:6)
)

df_que_me_pasaron

# Usamos la fila 2 como nombres de columnas
row_to_names(df_que_me_pasaron, row_number = 2)

# Caso con mÃ¡s NAs antes del encabezado
df_que_me_pasaron <- data.frame(
  X_1 = c(NA, NA, NA, "ID", 1:3),
  X_2 = c(NA, NA, NA, "Value", 4:6)
)

df_que_me_pasaron

# Fijamos la fila 4 como nombres correctos
row_to_names(df_que_me_pasaron, row_number = 4)
```



## ğŸ”„ TransformaciÃ³n de datasets con `{tidyr}`


El paquete `{tidyr}` permite transformar datasets entre dos formatos comunes:

- **Ancho a largo** (`pivot_longer()`): convierte columnas en filas.
- **Largo a ancho** (`pivot_wider()`): convierte filas en columnas.

---

### ğŸ“Œ Argumentos clave de `pivot_longer()`

- `cols = ...`: columnas que se desea transformar en filas.
- `names_to`: nombre de la nueva columna que contendrÃ¡ los **nombres originales** de las columnas.
- `values_to`: nombre de la columna que contendrÃ¡ los **valores originales**.
- `names_prefix`: elimina un **prefijo especÃ­fico** de los nombres de columna.
- `names_pattern`: permite **extraer partes** de los nombres usando expresiones regulares (regex).

---

### ğŸ“Œ Argumentos clave de `pivot_wider()`

- `names_from`: especifica quÃ© columna se usarÃ¡ para **crear nuevos nombres de columna**.
- `values_from`: define quÃ© columna contiene los **valores que se colocarÃ¡n** en las nuevas columnas.
- `values_fill`: define quÃ© valor se utilizarÃ¡ para **rellenar los espacios vacÃ­os** (por defecto es `NA`).

ğŸ’¡ *Tip:* Estos cambios son esenciales en anÃ¡lisis longitudinales, reshaping de resultados o para preparar datos para visualizaciÃ³n o modelado.


```{r message=FALSE, warning=FALSE}

# ------------------------------------------------------
# ğŸ“¦ LibrerÃ­as
library(tidyr)
library(dplyr)
library(ggplot2)
library(tidyverse) 

# ------------------------------------------------------
# ğŸ” pivot_longer: tabla ancha a larga
df <- data.frame(estudiante = c('Pedro', 'Pablo', 'Lorena', 'Eugenia'),
                 mes1 = c(8, 10, 6, 5),
                 mes2 = c(9, 4, 7, 8))

df |> pivot_longer(cols = c('mes1', 'mes2'),
                   names_to = 'periodo',
                   values_to = 'calif')

# ğŸ“¥ Ejemplo web
datos_genes <- read.delim("https://davetang.org/file/TagSeqExample.tab", header = TRUE)
datos_genes |> pivot_longer(cols = -gene, names_to = "muestra", values_to = "conteo") |> head()

# ------------------------------------------------------
# ğŸ“Š Ejemplo real con dataset `billboard`
library(tidyverse)

datos <- as_tibble(tidyr::billboard)


# Pivot largo con limpieza de nombre
datos_largos <- datos |> pivot_longer(cols = starts_with("wk"),
                                      names_to = "week",
                                      names_prefix = "wk",
                                      values_to = "rank",
                                      values_drop_na = TRUE) #|> head()

# Convertimos a numÃ©rica y resumimos
datos_largos <- datos_largos |> mutate(week = as.numeric(week)) 
datos_resumen <- datos_largos |>
  group_by(artist, track, date.entered) |>
  summarise(max_sem = max(week),
            min_ranking = min(rank),
            max_ranking = max(rank)) |>
  ungroup() |>
  mutate(dia_anio = lubridate::yday(date.entered)) #|> head()

# Graficar por periodos
datos_resumen |> filter(date.entered <= "1999-12-31") |> 
  ggplot(aes(x = reorder(track, -dia_anio), y = max_sem)) +
  geom_bar(stat = "identity") + coord_flip()

# ------------------------------------------------------
# ğŸª„ pivot_longer con patrÃ³n de nombre: WHO dataset
who |> pivot_longer(cols = new_sp_m014:newrel_f65,
                    names_to = c("diagnosis", "gender", "age"),
                    names_pattern = "new_?(.*)_(.)(.*)",
                    values_to = "count") |> head()

# ------------------------------------------------------
# ğŸ“ Ejemplo con `anscombe` usando names_pattern
datos_anscombe <- anscombe %>%
  pivot_longer(everything(), names_to = c(".value", "set"),
               names_pattern = "(.)(.)")

# Graficar Anscombe
datos_anscombe |> ggplot(aes(x = x, y = y, color = set)) +
  geom_point() + facet_wrap(~set) + theme_light()

# Medias iguales a pesar de grÃ¡ficas diferentes
datos_anscombe |> group_by(set) |> summarise(x_media = mean(x), y_media = mean(y))

# ------------------------------------------------------
# â¬†ï¸ pivot_wider: largo a ancho

df <- data.frame(estudiante = rep(c('Ariana', 'Daniel'), each=4),
                 anio = rep(c(1, 1, 2, 2), times=2),
                 semestre = rep(c('primavera', 'otonio'), times=4),
                 calif = c(84, 60, 78, 77, 62, 99, 88, 74))

df |> pivot_wider(names_from = semestre, values_from = calif)

# Otro ejemplo con datos mensuales
df <- data.frame(anio = rep(2024:2025, each = 12),
                 mes = rep(month.name, times = 2))
set.seed(06032025)
df <- df |> mutate(medicion = 100 * runif(n()))
df |> pivot_wider(names_from = "mes", values_from = "medicion")

# ------------------------------------------------------
# ğŸŸ Ejemplo con `fish_encounters`
fish_encounters |> pivot_wider(names_from = station, values_from = seen) |> head()
fish_encounters |> pivot_wider(names_from = station, values_from = seen, values_fill = 0) |> head()

# ------------------------------------------------------
# ğŸ  Ejemplo con `us_rent_income`
us_rent_income |> pivot_wider(names_from = variable, values_from = c(estimate, moe)) |> head()

# ------------------------------------------------------
# ğŸ§  Mini ejercicio final
df <- data.frame(estudiante = c('Berenice', 'Berenice', 'Leo', 'Leo', 'Frida', 'Frida'),
                 anio = c(2024, 2025, 2024, 2025, 2024, 2025),
                 puntos = c(22, 29, 18, 11, 12, 19),
                 retardos = c(2, 3, 6, 8, 5, 2)) |> head()

df
```



## ğŸ› ï¸ Transformaciones avanzadas con `{tidyr}`: combinar, separar, rellenar y desanidar

### ğŸ“ Resumen: Funciones Ãºtiles de `{tidyr}` para manipulaciÃ³n avanzada

#### ğŸ”— `unite()`
- Combina varias columnas en una sola, uniendo su contenido con un separador definido.

#### ğŸ” `separate_longer_delim()`
- Divide el contenido de una celda en **mÃºltiples filas** usando un delimitador.

#### ğŸ” `separate_wider_delim()`
- Divide el contenido de una celda en **mÃºltiples columnas** con un delimitador.

#### âŒ `drop_na()`
- Elimina filas que contienen valores faltantes (`NA`). Puedes especificar columnas clave.

#### â• `fill()`
- Rellena valores faltantes (`NA`) usando los valores vÃ¡lidos anteriores o posteriores.
  - Ideal para estructuras tipo Excel donde ciertos valores aparecen una sola vez.

#### ğŸ” `replace_na()`
- Reemplaza `NA` por un valor especÃ­fico definido por el usuario.

---

### ğŸ“¦ Funciones para listas o estructuras anidadas

#### `unnest_longer()`
- Convierte elementos de listas en **mÃºltiples filas**.

#### `unnest_wider()`
- Convierte listas en **mÃºltiples columnas**.

#### `hoist()`
- Extrae componentes especÃ­ficos de listas anidadas y los coloca como columnas individuales.

---

#### ğŸ§® `rowwise()`
- Permite aplicar operaciones **por fila**, Ãºtil para trabajar con listas o realizar cÃ¡lculos personalizados fila por fila.

ğŸ’¡ *Tip:* Estas funciones son muy Ãºtiles cuando los datos vienen mal estructurados, o cuando se trabaja con APIs, listas anidadas o formularios mal formateados.


```{r message=FALSE, warning=FALSE}


# ------------------------------------------------------
# ğŸ“Œ Ejemplo 1: Combinar columnas con unite()

df <- data.frame(estudiante = c('Berenice', 'Berenice', 'Leo', 'Leo', 'Frida', 'Frida'),
                 anio = c(2024, 2025, 2024, 2025, 2024, 2025),
                 puntos = c(22, 29, 18, 11, 12, 19),
                 retardos = c(2, 3, 6, 8, 5, 2))

df |> unite(c(puntos, retardos), col = "puntos_y_retardos", sep = "-")

df <- df |> mutate(reportes = c(2, 3, 3, 2, 1, 0))
df |> unite(c(puntos, retardos, reportes), col = "mounstrosa", sep = "/")

# ------------------------------------------------------
# ğŸ“Œ Ejemplo 2: Separar columnas largas y limpiar

url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/details.csv"
datos <- readr::read_csv(url) |> select(id, primary, boardgamecategory) |> head()

# Separar categorÃ­a en mÃºltiples filas
datos |> separate_longer_delim(boardgamecategory, delim = ", ") |> head()

# Limpiar los caracteres especiales
library(stringr)
patron <- c(`[` = "", `]` = "", `"` = "", `'` = "") |> coll()
datos |> separate_longer_delim(boardgamecategory, delim = ", ") |>
  mutate(boardgamecategory_limpio = str_replace_all(boardgamecategory, pattern = patron)) |> head()

# ------------------------------------------------------
# ğŸ“Œ Ejemplo 3: Separar en mÃºltiples columnas

datos <- data.frame(anio = c(2024, 2024, 2025),
                    inventario = c("vanilla,1.30", "chocolate,1.50", "fresa,1.00"))
datos |> separate_wider_delim(inventario, delim = ",", names = c("sabor", "precio"))

# ------------------------------------------------------
# ğŸ“Œ Ejemplo 4: Rellenar y limpiar datos

df <- data.frame(x1 = c("A", "B", "C", "D", "E", "F"),
                 x2 = c(1, NA, NA, 4, NA, 7))

df |> drop_na(x2)
df |> fill(x2)
df |> fill(x2, .direction = "up")
df |> replace_na(replace = list(x2 = pi))

# ------------------------------------------------------
# ğŸ“Œ Ejemplo 5: Desanidar columnas listas (`unnest` y `hoist`)

library(dplyr)
sub_datos <- starwars |> head(15)

# Expandir listas en columnas
sub_datos |> select(name, films) |> unnest_longer(films)
sub_datos |> select(name, films) |> unnest_wider(films, names_sep = "_")
sub_datos |> select(name, films) |> hoist(films, primera = 1, segunda = 2)

# Agrupar vehÃ­culos y naves por personaje
sub_datos |> rowwise() |>
  mutate(transporte = list(append(vehicles, starships))) |>
  unnest_longer(transporte) |> head()

# Contar nÃºmero de transportes por personaje
starwars |> rowwise() |> mutate(num_transportes = length(c(vehicles, starships))) |> head()

```



## âœ¨ Limpieza y manipulaciÃ³n de texto con `{stringr}`

#### ğŸ”¤ ManipulaciÃ³n y transformaciÃ³n de texto

- `tolower()`, `toupper()`: convierten cadenas de texto a minÃºsculas o mayÃºsculas, respectivamente.
- `paste()`, `paste0()`: combinan mÃºltiples strings. `paste()` permite definir un separador con `sep =`, mientras que `paste0()` los une directamente.

#### ğŸ” SeparaciÃ³n, conteo y detecciÃ³n de patrones

- `str_split()`, `str_split_fixed()`, `str_split_i()`: separan texto en partes usando un patrÃ³n (por ejemplo, espacios, comas o guiones).
- `str_count()`: cuenta cuÃ¡ntas veces aparece un patrÃ³n dentro de cada string.
- `str_detect()`: devuelve `TRUE` o `FALSE` si el patrÃ³n estÃ¡ presente en el texto.
- `str_replace_all()`: reemplaza **todas** las apariciones de un patrÃ³n por otro valor.
- `str_extract_all()`: extrae **todas** las coincidencias de un patrÃ³n (regex) de un string.

---

### ğŸ”§ Modificadores Ãºtiles para trabajar con patrones

- `coll()`: permite controlar la **sensibilidad a mayÃºsculas/minÃºsculas** y configurar la **localizaciÃ³n regional**. Por ejemplo, puedes ajustar el comportamiento para idiomas como el turco.
- `fixed()`: interpreta el patrÃ³n como **texto literal**, no como expresiÃ³n regular. Es Ãºtil cuando no se desea evaluar caracteres especiales como `.` o `*`.

ğŸ’¡ *Tip:* La mayorÃ­a de estas funciones provienen del paquete `{stringr}`, que ofrece una sintaxis coherente y poderosa para trabajar con texto en R.



```{r message=FALSE, warning=FALSE}

# ğŸ”¡ Transformaciones bÃ¡sicas

mi_string <- "Ejemplo de STRING, con caraceteres varios (12, 15 y 10.2)?!"
tolower(mi_string)

otro_string <- "Wow, tengo mÃ¡s que decir!!"
paste(mi_string, otro_string, sep = " ")
paste(mi_string, otro_string, sep = "@@@@")
paste(mi_string, otro_string)
paste0(mi_string, otro_string)

# ------------------------------------------------------
# ğŸ“¦ Separaciones, divisiones, conteo

stringr::str_split(string = mi_string, pattern = " ")
stringr::str_split(string = mi_string, pattern = boundary("word"))
stringr::str_count(string = mi_string, pattern = " ")
stringr::str_count(string = mi_string, pattern = boundary("word"))

# ------------------------------------------------------
# ğŸ Ejemplo con frutas y separaciÃ³n fija

fruits <- c("apples and oranges and pears and bananas",
            "pineapples and mangos and guavas")

fruits |> stringr::str_split(pattern = " and ")
fruits |> stringr::str_split(pattern = " and ", simplify = TRUE)
fruits |> stringr::str_split(pattern = " and ", n = 3)
fruits |> stringr::str_split(pattern = " and ", n = 2)
fruits |> stringr::str_split_fixed(pattern = " and ", n = 3)
fruits |> stringr::str_split_i(pattern = " and ", i = 2)
fruits |> stringr::str_split_i(pattern = " and ", i = -1)

# ------------------------------------------------------
# ğŸ§  Collation y sensibilidad a mayÃºsculas/minÃºsculas (Turco)

infierno_de_i <- c("istanbul", "Ä°zmar", "Istanbul", "izmar", "\u0130")

# ComparaciÃ³n sensible a mayÃºsculas
stringr::str_detect(infierno_de_i, pattern = coll("i", TRUE))

# ComparaciÃ³n con configuraciÃ³n regional turca
stringr::str_detect(infierno_de_i, coll("i", TRUE, locale = "tr"))

# ComparaciÃ³n como string fijo, sensible a mayÃºsculas
stringr::str_detect(infierno_de_i, fixed("i", TRUE))

# ------------------------------------------------------
# ğŸ” Reemplazos y extracciÃ³n con expresiones regulares

str_split(mi_string, pattern = "!")[[1]] -> mi_string_en_vector
grep(pattern = "\\?", x = mi_string_en_vector)

stringr::str_replace_all(mi_string, "e", "@@")
stringr::str_extract_all(mi_string, "[0-9]+")
stringr::str_extract_all(mi_string, "[?]+")
stringr::str_extract_all(mi_string, "[a-z]+")
stringr::str_extract_all(mi_string, regex("[a-z]+", ignore_case = TRUE))
```



## ğŸ§¼ Limpieza y anÃ¡lisis de texto: expresiones regulares y nubes de palabras

### ğŸ“ Resumen: Limpieza y anÃ¡lisis de texto con `stringr` y `quanteda`

#### âœ‚ï¸ Limpieza de texto con `stringr::str_extract()`

- `"\\d"`: extrae **dÃ­gitos individuales**.
- `"[a-z]+"`: extrae **cadenas de letras minÃºsculas**.
- `"\\b[a-z]+\\b"`: extrae **palabras completas** usando *word boundaries* (`\\b`).
- `group = n`: permite extraer un **grupo especÃ­fico** (definido por parÃ©ntesis en la expresiÃ³n regular).

---

#### ğŸ“„ Lectura de texto plano

- `read.delim()`: permite cargar archivos `.txt` como **documentos de texto plano**, Ãºtil para trabajar con discursos, ensayos, artÃ­culos, etc.

---

#### ğŸ§  AnÃ¡lisis textual con `{quanteda}`

- `tokens()`: divide el texto en **tokens** (palabras, signos de puntuaciÃ³n, etc.).
- `tokens_remove()`: elimina *stopwords*, es decir, palabras comunes sin significado importante (`el`, `la`, `de`, `y`, etc.).
- `dfm()`: convierte los tokens en una **matriz documento-frecuencia**, donde las filas son documentos y las columnas son palabras.
- `textplot_wordcloud()`: genera una **nube de palabras** para visualizar la frecuencia de tÃ©rminos mÃ¡s comunes en el texto.

ğŸ’¡ *Tip:* La combinaciÃ³n de limpieza con `stringr` y anÃ¡lisis con `quanteda` permite realizar anÃ¡lisis de texto cuantitativo de manera eficiente y reproducible.



```{r message=FALSE, warning=FALSE}
library(quanteda)
library(quanteda.textplots)


# ------------------------------------------------------
# ğŸ“Œ Ejemplos de extracciÃ³n con str_extract

mi_vector <- c("123 grapes", "apples x4", "bag of flour",
               "kiwi and lime", "Bag of sugar", "milk x2")

str_extract(mi_vector, "\\d")
str_extract_all(mi_vector, "\\d")

str_extract(mi_vector, "[a-z]+")
str_extract(mi_vector, "[a-z]{1,4}")
str_extract(mi_vector, "\\b[a-z]+\\b")
str_extract(mi_vector, "([a-z]+) of ([a-z]+)")
str_extract(mi_vector, "([a-z]+) of ([a-z]+)", group = 1)
str_extract(mi_vector, "([a-z]+) of ([a-z]+)", group = 2)

# ------------------------------------------------------
# ğŸ“„ Lectura de discurso y anÃ¡lisis bÃ¡sico

setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
mi_texto <- read.delim("./ObamaSpeech.txt", header = FALSE)
str(mi_texto)

# Resumen como corpus
mi_texto[1,1] |> corpus() |> summary()

# Matriz documento-frecuencia
mi_texto[1,1] |> quanteda::tokens() |> dfm()

# Palabras vacÃ­as en distintos idiomas
head(stopwords("en"), 20)
head(stopwords("es"), 10)

# Eliminar stopwords del discurso
mi_texto[17,1] |> quanteda::tokens() |>
  tokens_remove(stopwords("en")) |> dfm()

# ------------------------------------------------------
# ğŸŒ MÃºltiples frases + documento de texto + letras de canciÃ³n

primera_frase <- "This is $10 in 999 different ways,\n up and down; left and right!"
segunda_frase <- "@koheiw7 working: on #quanteda 2day\t4ever, http://textasdata.com?page=123."

texto_completo <- c(
  text1 = primera_frase,
  text2 = segunda_frase,
  text3 = mi_texto[17,1],
  text4 = mi_texto[27,1],
  text5 = mi_texto[37,1],
  text6 = mi_texto[47,1],
  text7 = mi_texto[57,1],
  text8 = billboard::lyrics[5, "lyrics"]
)

# ------------------------------------------------------
# ğŸ”¤ TokenizaciÃ³n y visualizaciÃ³n

# TokenizaciÃ³n bÃ¡sica
texto_completo |> quanteda::tokens()

# Nube de palabras con stopwords eliminadas
texto_completo |>
  quanteda::tokens() |>
  tokens_remove(stopwords("en")) |>
  dfm() |>
  textplot_wordcloud(min_count = 2)

# Nube sin nÃºmeros ni puntuaciÃ³n
texto_completo |>
  quanteda::tokens(remove_numbers = TRUE,
                   remove_punct = TRUE,
                   remove_separators = TRUE) |>
  dfm() |> textplot_wordcloud()

# Nube sin nÃºmeros, puntuaciÃ³n, separadores, y sin stopwords
texto_completo |>
  quanteda::tokens(remove_numbers = TRUE,
                   remove_punct = TRUE,
                   remove_separators = TRUE) |>
  tokens_remove(stopwords("en")) |>
  dfm() |> textplot_wordcloud()
```


# IntroducciÃ³n a datos en formato JSON

JSON (JavaScript Object Notation) es un formato de datos ligero que generalmente se utiliza para almacenar e intercambiar informaciÃ³n entre sistemas.

Es "fÃ¡cil" de leer y escribir para los humanos y sencillo de analizar y generar para las computadoras.

JSON se usa frecuentemente en aplicaciones web para transmitir datos entre un servidor y un cliente.

## CaracterÃ­sticas principales de JSON

Usa parejas clave-valor (llave-valor): Los datos se almacenan en pares de clave y valor (similar a los diccionarios en Python).

Ligero y legible: Es "fÃ¡cil" de entender y adecuado para la transmisiÃ³n de datos.

Independiente del lenguaje de programaciÃ³n: Aunque se basa en la sintaxis de JavaScript, JSON se puede utilizar con muchos lenguajes de programaciÃ³n (como R, Python, Java, C#, etc.).

Soporta estructuras anidadas: JSON puede representar datos complejos con arreglos y objetos.

Puede llevarte al infierno: Las ventajas de flexibilidad, eventualmente se convierten en su mayor desventaja, al tener datos almacenados sin ninguna estructura

Llevan a entender los elementos bÃ¡sicos de MongoDB (o DocumentDB) que es un framework de bases de datos NoSQL que almacena datos en documentos similares a JSON (en formato BSON).

AsÃ­ se puede ver un registro ("renglÃ³n") en formato JSON


## ğŸ§¾ IntroducciÃ³n al manejo de datos JSON en R con `{jsonlite}`



- El formato **JSON** (**JavaScript Object Notation**) es ampliamente utilizado para **intercambiar datos** entre aplicaciones, especialmente en la web (por ejemplo, en APIs).

---

### ğŸ“¦ Funciones clave del paquete `{jsonlite}`

- `fromJSON()`: convierte un archivo o string JSON a **objetos R** (listas, dataframes, etc.).
- `toJSON()`: convierte objetos R a JSON, ideal para enviar datos a APIs o guardarlos en archivos.
- Permite un **mapeo bidireccional sin pÃ©rdida de estructura**, funcionando bien con:
  - Dataframes
  - Listas anidadas
  - Vectores
  - Matrices

---

### âœ… Ventajas principales

- Ideal para trabajar con **APIs REST** u otras fuentes de datos web.
- Interpreta automÃ¡ticamente estructuras **anidadas, vacÃ­as o complejas**.
- Compatible con objetos comunes de R como **tibbles, listas y matrices**, listos para anÃ¡lisis.

ğŸ’¡ *Tip:* Puedes usar `pretty = TRUE` en `toJSON()` para obtener una versiÃ³n legible para humanos.


```{r message=FALSE, warning=FALSE}


# ------------------------------------------------------
# ğŸ“¦ Cargar librerÃ­as
library(jsonlite)
library(dplyr)
library(ggplot2)

# ------------------------------------------------------
# ğŸ“¥ Lectura de JSON tipo lista de objetos (estilo API)

json <- '
[
  {"Nombre" : "Mario", "Edad" : 32, "Ocupacion" : "Plumber"}, 
  {"Nombre" : "Peach", "Edad" : 21, "Ocupacion" : "Princess"},
  {},
  {"Nombre" : "Bowser", "Ocupacion" : "Koopa"}
]'

df <- json |> fromJSON()
df

# ------------------------------------------------------
# ğŸ” Convertir dataframe a JSON
df |> toJSON(pretty = TRUE)

# ------------------------------------------------------
# ğŸ§® Lectura de una matriz en JSON
json <- '[
  [1, 2, 3, 4],
  [5, 6, 7, 8],
  [9, 10, 11, 12]
]'
formato_matriz <- fromJSON(json)
formato_matriz
class(formato_matriz)

# ğŸ” De matriz en R a JSON
formato_matriz |> toJSON(pretty = TRUE)
```


## ğŸ§¾ Lectura de datos JSON en R: casos simples y estructuras complejas


### ğŸ“ Resumen: Lectura de datos JSON con `fromJSON()` (`{jsonlite}`)

La funciÃ³n `fromJSON()` permite leer datos en formato **JSON** desde un texto o una URL, y devuelve un objeto R dependiendo de la estructura del JSON.

---

### âœ”ï¸ Comportamiento segÃºn estructura del JSON

- Arreglo de **primitivos** (nÃºmeros, cadenas): se convierte en un **vector**.
- Arreglo de **objetos** (llaves y valores): se convierte en un **dataframe**.
- Arreglo de **arreglos uniformes** (listas de misma longitud): se convierte en una **matriz**.
- JSON **anidado o complejo**: se convierte en una **lista**, que puede requerir procesamiento adicional con `purrr`, `tidyr` o `dplyr`.

---

### ğŸ“Œ Argumentos Ãºtiles de `fromJSON()`

- `simplifyVector = TRUE`: convierte arreglos planos a vectores (por defecto estÃ¡ activado).
- `simplifyDataFrame = TRUE`: convierte listas de objetos con las mismas llaves a un dataframe.
- `simplifyMatrix = TRUE`: convierte listas de listas numÃ©ricas de igual tamaÃ±o en una matriz.

ğŸ’¡ *Tip:* Si el resultado es una lista anidada, puedes explorarla con funciones como `str()` o `names()` y luego transformarla con `tidyjson` o `jsonlite::flatten()` si es necesario.


```{r message=FALSE, warning=FALSE, echo = TRUE, results = "hide"}


# Arreglo de strings
'["Amsterdam", "Rotterdam", "Utrecht", "Den Haag"]' |> fromJSON(simplifyVector = TRUE)

# Arreglo de objetos (JSON tipo tabla)
'[{"name":"Erik", "age":43}, {"name":"Anna", "age":32}]' |> fromJSON()

# Matriz numÃ©rica
'[[1, 2, 3], [4, 5, 6]]' |> fromJSON(simplifyMatrix = TRUE)

# Arreglo desigual (convierte a lista, no matriz)
'[[1, 2, 3], [4, 5, 6], [5, 6]]' |> fromJSON(simplifyMatrix = TRUE)

# Mezcla de tipos (convierte todo a strings)
'[[1, 2, 3], [4, "5", 6]]' |> fromJSON(simplifyMatrix = TRUE)

# ------------------------------------------------------
# ğŸ“Œ Formato estilo "columnas" (JSON tipo lista por nombre de columna)

json <- '
{ 
   "ID":["1","2","3","4","5"],
   "Name":["Alejandra","Esteban","Susana","Julian","Karina"],
   "Salary":["722.5","815.2","1611","2829","843.25"],
   "StartDate":["6/17/2014","1/1/2012","11/15/2014","9/23/2013","5/21/2013"],
   "Dept":["IT","IT","HR","Operations","Finance"],
   "Hand":["left","right","right","left", "both"]
}'
json |> fromJSON()
json |> fromJSON() |> as.data.frame()

# ------------------------------------------------------
# ğŸŒ Lectura desde URL pÃºblica (API)

url <- "https://data.ny.gov/api/views/9a8c-vfzj/rows.json?accessType=DOWNLOAD"
datos_descargados <- fromJSON(url) |>head()

# Revisamos clase y estructura general
#class(datos_descargados)
head(datos_descargados, 2) |> head()

# Segunda entrada es la Ãºtil: contiene los datos
datos_descargados[2] |> head()
str(datos_descargados[['data']]) |> head()

# Guardamos subconjunto
subcjto <- datos_descargados[['data']] |> head()
#class(subcjto)
names(subcjto) |> head()

# Consultamos una columna de la matriz (ejemplo: columna 14)
class(subcjto[,14])|> head()

# Convertimos a dataframe para trabajar mÃ¡s fÃ¡cilmente
as.data.frame(subcjto) |> head()
```




## ğŸ§¹ ExploraciÃ³n, limpieza y anÃ¡lisis de columnas desde datos JSON

### ğŸ“ Resumen: ExploraciÃ³n de JSONs complejos en R

- Al importar JSONs complejos, es comÃºn que algunas columnas aparezcan con nombres genÃ©ricos como `V1`, `V2`, etc.
- Se recomienda:
  - **Seleccionar solo las columnas relevantes**.
  - Explorar el contenido con `str()` o `glimpse()` antes de operar sobre ellas.

- Algunas columnas pueden contener **listas anidadas**, lo cual requiere atenciÃ³n especial antes de aplicar funciones vectorizadas o transformaciones.

---

### ğŸ“Œ Lectura recomendada

- `read_json(..., simplifyVector = TRUE)` permite convertir automÃ¡ticamente **estructuras planas** o semi-planas en `data.frames`.

ğŸ’¡ *Tip:* Para JSONs complejos anidados, considera usar `jsonlite::flatten()` o herramientas como `purrr::map()` y `tidyjson` para acceder a niveles internos.



```{r message=FALSE, warning=FALSE, echo = TRUE, results = "hide"}

df_negocios <- subcjto |> as.data.frame() |> dplyr::select(V1, V9:V14, V16, V19, V20)

# Vemos los valores Ãºnicos para decidir si eliminamos columnas
df_negocios |> select(V20) |> unique()
df_negocios |> select(V9) |> unique()
df_negocios |> select(V19) |> unique()
df_negocios |> select(V11) |> unique()  # Potencialmente basura
df_negocios |> select(V12) |> unique()  # Potencialmente basura

# Conteo de registros por condado
df_negocios |> group_by(V9) |> summarise(conteo = n()) |> ungroup() |> arrange(desc(conteo))

# Conteo conjunto por condado y categorÃ­a
df_negocios |> group_by(V9, V19) |> summarise(conteo = n()) |> ungroup() |> arrange(desc(conteo))

# Conteo de categorÃ­as Ãºnicas por condado
df_negocios |> select(V9, V19) |> group_by(V9) |> summarise(conteo = n()) |> ungroup() |> arrange(desc(conteo))

# ------------------------------------------------------
# ğŸ“„ Lectura de un archivo JSON estructurado desde archivo local
setwd("C:/Users/ferna/Documents/Diplomado_Data_Sience/Estudio/Data")
datos <- read_json("datos_prueba.json")
class(datos)
str(datos)
dim(datos)
head(datos, 2)

# Simplificamos para convertir en dataframe directo
datos_df <- read_json("datos_prueba.json", simplifyVector = TRUE)
class(datos_df)
str(datos_df)
head(datos_df)
dim(datos_df)

# Ver columnas que aÃºn contienen listas
datos_df |> select(where(is.list))

# Ejemplo de elemento anidado
datos_df$F_liv[1]

# Convertimos un registro nuevamente a JSON
datos_df |> head(1) |> toJSON(pretty = TRUE)
```


