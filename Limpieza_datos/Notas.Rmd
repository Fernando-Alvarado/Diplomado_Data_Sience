# Notas

Aqui pondre las cosdas mas importantes de este modulo para estudiar

## Indice 

- Lubridate (Manejo de fechas)
- Janitor   (Limpieza de datos df)
- Manejo de NAs 
- visdat  (visualizar NAs)
- naniar  (transformar NAs y hacer un poco de estadisticas con ellos)
- simputation (En caso de no borrar los NAs, podemos simularlos con regresion, etc)
- mice imputr valores faltantes
- rpart      Arboles de decicion, para hacer regresiones mas eficientes
- recipes  preprocesamiento de datos



# Clase 3

### Repaso de lubridate

El paquete lubridate en R se usa para manipular y trabajar con fechas y horas de manera sencilla. Facilita la conversión, extracción y operación con datos de tipo date-time (POSIXct, POSIXlt, Date), lo que ayuda a evitar errores comunes en el manejo de fechas.

```{r}

library(lubridate) # Sirve para manejar algunas variables de fecha

library(lubridate)

# Crear una fecha desde un string
fecha <- ymd("2024-03-04")
print(fecha)  # Devuelve: "2024-03-04"

# Extraer componentes de la fecha
año <- year(fecha)     # 2024
mes <- month(fecha)    # 3
dia <- day(fecha)      # 4

# Crear fecha y hora
fecha_hora <- ymd_hms("2024-03-04 14:30:45")
print(fecha_hora)  # "2024-03-04 14:30:45 UTC"

# Sumar o restar tiempo
nueva_fecha <- fecha + days(10)  # Sumar 10 días
print(nueva_fecha)  # "2024-03-14"

# Identificar el día de la semana
dia_semana <- wday(fecha, label = TRUE, abbr = FALSE)
print(dia_semana)  # "lunes"

# Convertir un string con formato ambiguo
fecha2 <- dmy("04-03-2024")  # Día-Mes-Año
print(fecha2)  # "2024-03-04"

```


#### Funciones útiles de lubridate
- ymd(), mdy(), dmy(): Convertir strings en fechas.
- ymd_hms(), mdy_hms(), dmy_hms(): Fechas con horas, minutos y segundos.
- year(), month(), day(), wday(): Extraer partes de la fecha.
- hour(), minute(), second(): Extraer partes de la hora.
- days(), months(), years(): Para sumar o restar tiempo.



### Repaso Janitor

El paquete janitor en R se utiliza para limpiar y organizar datos de manera eficiente. Es especialmente útil cuando trabajas con data frames desordenados o con nombres de columnas inconsistentes.



```{r}

library(janitor)
library(dplyr)  # Para manipulación de datos

# Crear un data frame con problemas
df <- data.frame(
  "Nombre Cliente" = c("Ana", "Carlos", "Beatriz"),
  " Ventas 2024 " = c(100, 200, 150),
  "Categoría" = c("A", "B", "A")
)

#  Limpiar nombres de columnas
df_limpio <- clean_names(df)
print(df_limpio)

```
+ Limpia de forma automatica el nombre de las columnas

Resultado 
  nombre_cliente ventas_2024 categoria
1          Ana         100         A
2       Carlos         200         B
3      Beatriz         150         A


+ Borra files de forma inmediata

```{r}
df2 <- data.frame(
  id = c(1, 2, 2, 3),
  valor = c(10, 20, 20, 30)
)

df2_sin_duplicados <- df2 %>% remove_duplicate_rows()
print(df2_sin_duplicados)

```


Detectar valores vacíos o NA

+ tabyl() genera una tabla de frecuencia rápida.


```{r}
df3 <- data.frame(
  producto = c("A", "B", "C"),
  precio = c(100, NA, 200)
)

# Revisar valores faltantes
tabyl(df3, precio)

```



La función compare_df_cols_same() se usa para comparar las columnas de diferentes data frames y verificar si tienen el mismo tipo de datos (data type).

Esto es útil cuando trabajas con múltiples data frames y necesitas asegurarte de que las columnas coincidan en sus tipos antes de unirlos (merge, bind_rows, join), evitando errores por diferencias en los tipos de datos.



```{r}
# Creamos dos data frames con columnas similares pero con diferencias en los tipos de datos
df1 <- data.frame(
  id = c(1, 2, 3),
  nombre = c("Ana", "Carlos", "Beatriz"),
  ventas = c(100, 200, 150)
)

df2 <- data.frame(
  id = c("1", "2", "3"),  # Aquí 'id' es de tipo character, no numérico
  nombre = c("Ana", "Carlos", "Beatriz"),
  ventas = c(100, 200, 150)
)

# Comparar las columnas de los dos data frames
compare_df_cols_same(df1, df2)
```

resultado FALSE


La función adorn_percentages() del paquete {janitor} se usa para calcular porcentajes dentro de una tabla de frecuencia creada con tabyl(). Dependiendo del argumento que uses ("row", "col", "all"), los porcentajes se calculan en diferentes direcciones.

```{r}
# mtcars %>%
#  tabyl(gear, cyl) %>%      # Crea una tabla de frecuencia de 'gear' y 'cyl'
#  adorn_totals("col") %>%   # Agrega una columna con el total de cada fila
#  adorn_percentages("row")  # Convierte los valores en porcentajes por fila
  

# mtcars %>%
#  tabyl(gear, cyl) %>%
#  adorn_totals("col") %>%
#  adorn_percentages("row") %>%
#  adorn_pct_formatting(digits = 2)  

```


+ Otra función útil, es saber si ya renglones duplicados

```{r}
get_dupes(dat = mtcars)
```

+ Este dataset completo tiene sus renglones diferentes todos

+ Pero también podemos saber si hay idénticos restringiéndonos a algunas columnas

+ Por ejemplo, estamos preguntándole si hay dos rengloncitos idénticos sólo considerando los variables wt y cyl

```{r}
get_dupes(dat = mtcars, wt, cyl)
```

+ Un uso común es para verificar si la columna que creemos que es un ID efectivamente lo es

```{r}
get_dupes(dat = datos_ventas, id_venta)
```

+ Otra función super popular es get_one_to_one(), esta función muestra que columnas (si es que las hay)
tienen relaciones uno a uno entre sí. Es decir, si podríamos formar una función biyectiva entre dos columnas


#### get_one_to_one() en {janitor}
La función get_one_to_one() se usa para detectar relaciones uno a uno en un conjunto de datos, es decir, verifica si cada valor único de una columna tiene exactamente un valor correspondiente en otra columna.

Esto es útil cuando trabajas con data frames y necesitas validar si hay una correspondencia exacta entre dos variables antes de hacer joins o análisis.

- Ejemplo donde si 

```{r}
library(janitor)

# Creamos un data frame con una relación 1 a 1
df <- data.frame(
  id = c(1, 2, 3, 4),
  nombre = c("Ana", "Carlos", "Beatriz", "David")
)

# Verificamos si hay una relación 1 a 1 entre 'id' y 'nombre'
get_one_to_one(df, id, nombre)
```

Resultado: TRUE

- Ejemplo con una relación NO 1 a 1
Si hay valores duplicados en alguna de las columnas, la relación no será 1 a 1:

```{r}
df2 <- data.frame(
  id = c(1, 2, 2, 4),  # 'id' 2 aparece dos veces
  nombre = c("Ana", "Carlos", "Beatriz", "David")
)

get_one_to_one(df2, id, nombre)

```

Resultado: FALSE

### Manejo de NAs (primera visita)

```{r}
mi_dataframe <- data.frame(v1 = c(1, NA, 3),
                           v2 = c(NA, NA, NA),
                           v3 = c("a", NA, "b"))

mi_dataframe
```

Una primera solución rápida, pero probablemente incorrecta es quitar los renglones y columnas que tienen NA (esto es muy drástico)

```{r}
mi_dataframe |> remove_empty(c("rows", "cols"))
```

### Libreria visdat 

El paquete visdat se usa para visualizar la estructura y calidad de los datos en un data frame de manera rápida y efectiva. Es útil para detectar valores faltantes, tipos de datos y posibles inconsistencias antes de hacer limpieza de datos.

Para practicar puedes usar los datos airquality

+ Qué hace?

- Muestra los tipos de datos de cada columna en colores diferentes.
- Identifica rápidamente columnas con valores faltantes (NA).

```{r}
library(visdat)

# Cargar datos de ejemplo
data("airquality")

# Visualizar la estructura del dataset
vis_dat(airquality)
```

crea una grafica, para visualizar cuantos NA tenemos

+ Solo ver NaS

```{r}
vis_miss(airquality), grafica para solo visualizar NAs
```

+ Resalta valores que cumplen una condición (ejemplo: valores mayores a 100).

```{r}
vis_expect(airquality, ~ . > 100)
```

### Libreria naniar

El paquete naniar está diseñado para analizar y visualizar valores faltantes (NA) en los datos. Es muy útil cuando necesitas identificar patrones de datos ausentes y decidir cómo manejarlos (imputación, eliminación, etc.).


```{r}
library(naniar)
```

- Muestra un gráfico donde cada fila es una observación y cada columna una variable.
- Resalta en color los valores que son NA.

```{r}
# Cargar datos de ejemplo
data("airquality")

# Visualizar valores faltantes
vis_miss(airquality)
```

+Sustituye valores específicos (-99) por NA en la columna score.

```{r}
df <- data.frame(
  id = c(1, 2, 3, 4),
  score = c(10, -99, 30, -99)  # -99 indica valores faltantes
)

# Reemplazar -99 por NA en la columna score
df_limpio <- df %>%
  replace_with_na(replace = list(score = -99))

print(df_limpio)
```

+ Crea un gráfico de barras con la cantidad de valores faltantes por columna.

```{r}
gg_miss_var(airquality)
```

+ La función `add_prop_miss()` me dice la proporción de faltantes por renglón

```{r}
datos %>%
  add_prop_miss() %>%
  head(n = 15)
```

+ Podemos hacer también un resumen de los faltantes por columna

```{r}
datos |> miss_var_summary()
```

+ Haciendo una grafica para ver los datos faltantes

```{r}
datos |> ggplot(aes(x = Solar.R, y = Ozone)) + 
  geom_miss_point()
```

+ Las funciones `shadow` sirven para hacer un seguimiento de los valores faltantes.

+ La función `as_shadow` crea un dataframe con el mismo conjunto de columnas, pero con los nombres de las columnas a los que se les añade un sufijo _NA.

```{r}
datos |> as_shadow()
datos |> bind_shadow() # Hace una tabla mas bonita
```

Funcion, para hacer estadisticas descriptivas de los NA y poder decidir como actuar frente a ellos

```{r}
datos %>% bind_shadow() %>% 
  group_by(Ozone_NA) %>% 
  summarise_at(.vars = "Solar.R",
               .funs = c("mean", "sd", "var", "min", "max"),
               na.rm = TRUE)
```

### Libreria simputation

```{r}
library(simputation)
```

+ La mayoría de sus métodos se basan en completar los datos faltantes con regresión

+ Recordatorio: La variable Ozone es la que queremos rellenar pues tiene muchos NAs

```{r}
datos_imp_reglin <- impute_lm(datos, Ozone ~ Temp + Wind)  # Rellena los datos usando regresion linal
```

Veamos como quedaron los datos

```{r}
library(naniar)
datos_imp_reglin |> miss_var_summary() #Nos da una proporcion de cuantos datos NAs tenemos
```
+ Ya "arreglé" el tema de NAs en la columna Ozone


```{r}
datos %>% bind_shadow() %>%
  as.data.frame() %>% 
  impute_lm(Ozone ~ Temp + Wind) %>%
  ggplot(aes(x = Temp,
             y = Ozone,
             colour = Ozone_NA)) + 
  geom_point()
```


### Libreria mice

El paquete mice (Multivariate Imputation by Chained Equations) en R se usa para imputar valores faltantes en conjuntos de datos mediante métodos estadísticos avanzados.

¿Para qué sirve mice?
- Rellena los valores faltantes en un data frame de manera adecuada, evitando sesgos en el análisis.
- Usa el método de imputación múltiple (Multiple Imputation), lo que significa que genera varias versiones del dataset con diferentes valores imputados, mejorando la robustez del análisis.
- Es útil cuando los datos faltan de forma aleatoria (Missing at Random, MAR).


```{r}
library(mice)

# Crear un data frame con valores faltantes
df <- data.frame(
  var1 = c(1, 2, NA, 4, 5),
  var2 = c(NA, 3, 4, NA, 6)
)

# Ver resumen de datos faltantes
md.pattern(df)

# Aplicar imputación con mice
imputed_data <- mice(df, method = "pmm", m = 5) 

# Obtener el dataset imputado
complete_data <- complete(imputed_data)

# Ver el dataset imputado
print(complete_data)
```

Explicación del código:

- md.pattern(df) → Muestra el patrón de valores faltantes en el dataset. mice(df, method = "pmm", m = 5):
- "pmm" (Predictive Mean Matching) es el método de imputación.
- m = 5 genera 5 versiones diferentes del dataset imputado.
- complete(imputed_data) → Extrae una versión del dataset con los valores imputados.


Te dice un patron de los datos que hacen falta

```{r}
datos |> md.pattern()
```


+ No solo podemos ajustar un modelo de regresion lineal, tambien podemos ajustar un modelo de arbol 
(CART: classification and regresion tree)

```{r}
datos_imp_arbol <- impute_cart(datos, Ozone ~ .)
```

### Libreria rpart

a librería rpart en R se utiliza para la construcción de árboles de decisión para clasificación y regresión. Es una de las implementaciones más comunes del algoritmo CART (Classification and Regression Trees).

Funciones principales:

- rpart() – Crea un árbol de decisión.
- printcp() – Muestra la tabla de costos de poda del árbol.
- plotcp() – Grafica la tabla de costos de poda.
- prune() – Poda el árbol para evitar sobreajuste.
- predict() – Realiza predicciones usando el árbol generado.
- summary() – Muestra detalles sobre el modelo ajustado.


```{r}
# Cargar la librería
library(rpart)

# Usar el dataset iris
data(iris)

# Crear un árbol de decisión para clasificar especies de flores
modelo <- rpart(Species ~ ., data = iris, method = "class")

# Visualizar el árbol generado
print(modelo)
plot(modelo)
text(modelo, use.n = TRUE)
```

Ejemplo de diplomado para entender los datos 

```{r}

datos %>%
  add_prop_miss() %>%
  rpart(prop_miss_all ~ ., data = .) %>%
  prp(type = 4, extra = 101, prefix = "Prop. Miss = ", cex=0.7) #Con cex, aumentas el tamaño del texto
```

```{r}

```

### recipes

La librería recipes en R se utiliza para la preprocesamiento de datos en modelos de aprendizaje automático. Forma parte del ecosistema tidymodels y permite definir pasos secuenciales para limpiar y transformar datos antes del modelado.

Funciones principales:

- recipe() – Crea una receta para procesar datos.
- step_center() – Centra las variables numéricas (resta la media).
- step_scale() – Escala las variables numéricas (divide por la desviación estándar).
- step_normalize() – Normaliza datos (resta la media y divide por la desviación estándar).
- step_dummy() – Convierte variables categóricas en variables dummy.
- prep() – Prepara la receta para ser aplicada a los datos.
- bake() – Aplica la receta a los datos nuevos.



```{r}
# Cargar librerías
library(recipes)
library(dplyr)

# Cargar datos
data(iris)

# Definir una receta para preprocesar los datos
receta <- recipe(Species ~ ., data = iris) %>%
  step_center(all_numeric()) %>%  # Centrar variables numéricas
  step_scale(all_numeric()) %>%   # Escalar variables numéricas
  step_dummy(all_nominal(), -all_outcomes()) # Convertir variables categóricas en dummies

# Preparar la receta
receta_prep <- prep(receta, training = iris)

# Aplicar la receta a los datos
iris_procesado <- bake(receta_prep, new_data = iris)

# Ver los primeros registros transformados
head(iris_procesado)
```

```{r}

```