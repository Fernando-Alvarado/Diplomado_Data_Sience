---
title: "Sesion 02"
author: "Eduardo Martínez"
date: "2025-03-01"
output: html_document
---

```{r}
#install.packages("readxl")
library(readxl) # Para leer archivos de Excel
library(dplyr)
library(ggplot2)
library(lubridate) # Sirve para manejar algunas variables de fecha
```

```{r}
library(maps)
```

```{r}
data_superstore <- readxl::read_xls("Sample - Superstore.xls")
```

```{r}
data_superstore |> head()
```

+ Primero generaremos el profit por estado

```{r}
data_por_estado <- data_superstore %>% dplyr::select(State, Profit) %>%
  group_by(State) %>% 
  summarise(ganancia = sum(Profit)) %>% 
  ungroup()

data_por_estado
```

+ Mi intención es hacer un mapa con las ganacias por estado

+ Para eso voy a ocupar la librería {maps}

+ Esta librería además de permitirte dibujar mapas, tiene algunos datasets "populares", entre ellos la lista de los estados de USA

```{r}
MainStates <- map_data("state")

MainStates
```

Podemos observar que tiene una columnita que se llama `region`

```{r}
MainStates |> dplyr::select(region) |> unique()
```

+ Para unir estas tablas, necesito que ambas tengan el mismo formato... Entonces convertiré la columna de estado en mi tabla de ganancias a minuscula

```{r}
data_por_estado
```

```{r}
data_por_estado <- data_por_estado %>%
  mutate(region = tolower(State)) #estoy convirtiendo a minusculas la columa State

data_por_estado
```

+ Voy a juntar mi tabla de latitudes y longitudes con mi tabla de datos de ganancias por estado 

```{r}
data_por_estado <- data_por_estado %>% inner_join(MainStates, by = "region")

data_por_estado
```

```{r}
data_por_estado %>% ggplot() + 
  geom_polygon(aes(x=long, y=lat, group=group, fill = ganancia), 
               color="white", linewidth = 0.2) +
  scale_fill_gradient2(low = "orange", 
                       mid = "lightskyblue3", high = "dodgerblue4", midpoint = 0) +
  theme_light() +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title = element_text(face = "bold", size = 9))
```

+ Híjole!! Yo no tengo mucha cultura de los estados de USA, creo que necesito unas etiquetitas

```{r}
df_para_etiquetas <- MainStates %>% group_by(region) %>% 
  summarise(long = median(long), lat = median(lat)) # En la coordenada mediana pondre las etiquetas

df_para_etiquetas
```

```{r}
library(ggrepel)
```


```{r}
data_por_estado %>% ggplot() + 
  geom_polygon(aes(x=long, y=lat, group=group, fill = ganancia), 
               color="white", linewidth = 0.2) +
  scale_fill_gradient2(low = "orange", 
                       mid = "lightskyblue3", high = "dodgerblue4", midpoint = 0) +
  geom_label_repel(data = df_para_etiquetas, aes(x=long, y=lat, label = region),
             color = "dodgerblue4", size = 2) +
  theme_light() +
  theme(axis.text.x = element_blank(),
        axis.title.x = element_blank(),
        axis.ticks.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        plot.title = element_text(face = "bold", size = 9))
```

+ A mí, Lalo no me encantan las visualizaciones con mapas por dos razones en particular:

+ Primera: Nuestro cerebro inmediatamente toma el área de la región como una característica importante y en realidad no lo es. Podríamos tener que el número de tiendas en Texas es 3 y el número tiendas en Vermont es 50... Dada la diferencia de áreas en el mapa de estas dos regiones podrían estar interpretando mal los datos.

+ Segunda: Dado que nuestro cerebro no se puede desapegar de las áreas de las regiones y los mapas son una proyección en 2D de las regiones originales (gracias cartógrafos) en realidad no estamos viendo el tamaño real de las regiones.

# Bases de datos más estructuradas

## SQLite

+ **SQLite** es un sistema de administración de bases de datos relacionales (RDBMS, Relational Database Management System)

+ Es ligero, serverless (sin servidor), self-contained (autónomo) e integrado (embedded)

+ Se utiliza para el almacenamiento local de datos en aplicaciones, prototipos y proyectos pequeños o medianos

## Ligero (y rápido):

+ SQLite está diseñado para ser ligero y eficiente, lo que lo hace ideal para aplicaciones con tráfico bajo o moderado, o para su uso en sistemas integrados.

+ Funciona bien para aplicaciones pequeñas, pero puede no ser adecuado para sistemas de alta concurrencia o a gran escala.

## Serverless:

+ A diferencia de bases de datos tradicionales como MySQL o PostgreSQL, SQLite no requiere un proceso de servidor por separado para funcionar.

+ La base de datos se almacena en un solo archivo en el disco, y la biblioteca lee y escribe directamente en ese archivo.

## Self-Contained:

+ Es un sistema autónomo, lo que significa que no tiene dependencias externas. Todo el motor de la base de datos está contenido dentro de una sola biblioteca.

## Configuración cero

+ No requiere configuración ni administración. No es necesario instalar un servidor, configurar usuarios o administrarar permisos.

## Base de datos en un solo archivo

+ Toda la base de datos (tablas, índices y datos) se almacena en un solo archivo en el disco (por ejemplo, `mibasededatos.db`). Por lo tanto es muy fácil copiar, mover o compartir la base de datos.

## Adicionales:

+ SQLite es multiplataforma y funciona en varios sistemas operativos, incluyendo Windows, macOS, Linux, iOS y Android.

+ Admite propiedades ACID (Atomicidad, Consistencia, Aislamiento, Durabilidad), lo que garantiza transacciones confiables incluso en caso de fallos del sistema.

+ Es open-source y se publica bajo dominio público, lo que significa que es gratis para cualquier uso sin restricciones de licencia.

# Empecenmos...

```{r}
library(DBI)
library(dbplyr)
library(RSQLite)
library(Lahman)
```

+ Una de las formas más fáciles es con la librería {DBI} utilizando la función `dbGetQuery()` 

+ Se hace copy/paste de código SQL en la función de R como un string entre comillas

+ Esta forma se conoce como **pass through SQL code**

+ Es decir, se escribe el query como string en R y la función `dbGetQuery()` la convierte en un query y manda la solicitud al sistema de bases de datos para ejecutar dicha query. Es decir, necesita una conexión

+ Lo primero que vamos a hacer una conexión

```{r}
conn <- DBI::dbConnect(RSQLite::SQLite(), "CarsDB.db")
```

+ Estoy generando una conexión con SQLite a una base de datos se llama CarsDB.db

+ Importante: Si la base de datos no existe la crea

+ ¿Qué tablas tiene esta base de datos?

```{r}
dbListTables(conn)
```

+ No tienes ninguna tabla en esa base de datos :(

+ Vamos a insertarle tablas

+ Voy a insertarle un dataset de R, que se llama `mtcars`


```{r}
mtcars |> head()
```

+ Primero notemos que los nombres no son parte de explícita del dataset, son nombres de renglón. Lo primero que haremos es integrarlos a una columna hecha y derecha

```{r}
datos <- mtcars
datos$car_names <- rownames(datos) # Creo una nueva columna que consiste de los nombre de los autos
rownames(datos) <- c() # Elimino los nombres de los renglones
head(datos)
```

+ Voy a insertar (o escribir) este dataframe en forma de tabla a nuestra base de datos (SQlite) con la conexión que ya generamos antes

```{r}
dbWriteTable(conn, name = "cars_data", value = datos)
```

+ Veamos que tablas tenemos ahora en nuestra bases de datos (SQlite)


```{r}
dbListTables(conn)
```

+ Ah!! Ya tengo al menos una tabla

+ Como ya tenemos una tabla, hagamos nuestra primera query

```{r}
dbGetQuery(conn, "SELECT * FROM cars_data")
```

+ ¿Oye y qué tipo de objeto este que nos regresa?

```{r}
dbGetQuery(conn, "SELECT * FROM cars_data") |> class()
```
+ Hagamos otro query

```{r}
dbGetQuery(conn, "SELECT * FROM cars_data LIMIT 10")
```

+ Me parece un poco más limpia la siguiente sintaxis

```{r}
mi_query <- "SELECT * FROM cars_data LIMIT 10"
dbGetQuery(conn, mi_query)
```

+ Hagamos otros queries

```{r}
# Obtener los car names y caballos de fuerza (hp) que 8 cilindros
dbGetQuery(conn,"SELECT car_names, hp, cyl FROM cars_data
                 WHERE cyl = 8")
```


```{r}
# Obtener los car names y caballos de fuerza (hp) que empiezan con 'M' y que tienen 6 o 8 cilindros
dbGetQuery(conn,"SELECT car_names, hp, cyl FROM cars_data
                 WHERE car_names LIKE 'M%' AND cyl IN (6,8)")
```


```{r}
# Obtener los caballos de fuerza (hp) promedio y millas por galón (mpg) promedio por número de cilindros
dbGetQuery(conn,"SELECT cyl, AVG(hp) AS 'average_hp', AVG(mpg) AS 'average_mpg' FROM cars_data
                 GROUP BY cyl
                 ORDER BY average_hp")

```
Voy a generar un objeto con esta tabla

```{r}
resumen <- dbGetQuery(conn,"SELECT cyl, AVG(hp) AS 'average_hp'FROM cars_data
                 GROUP BY cyl
                 ORDER BY average_hp")
```

```{r}
class(resumen)
```

+ Me gustaría insertar (escribir) otras tablas

```{r}
autos <- c('Camaro', 'California', 'Mustang', 'Explorer')
fabricante <- c('Chevrolet','Ferrari','Ford','Ford')
df1 <- data.frame(autos, fabricante)
df1
```

```{r}
autos <- c('Corolla', 'Lancer', 'Sportage', 'XE')
fabricante <- c('Toyota','Mitsubishi','Kia','Jaguar')
df2 <- data.frame(autos, fabricante)
df2
```

+ Voy a juntar estos dataframes en una lista (para poder insertarlos juntos)

```{r}
lista_dfs <- list(df1,df2)
lista_dfs
```

+ Vamos a escribir una nueva tabla en SQLite que este formada por estos dos dataframes juntos

```{r}
# Se escribe una nueva tabla haciendo appending de los dataframes de la lista
for(k in 1:length(lista_dfs)){
    dbWriteTable(conn, name = "otros_autos", value = lista_dfs[[k]], append = TRUE)
}
```

+ Qué tablas tenemos hasta el momento?

```{r}
dbListTables(conn)
```

+ Hagamos una query en esta segunda tabla

```{r}
dbGetQuery(conn, "SELECT * FROM otros_autos")
```

+ Podemos parametrizar con objetos de R, las queries

```{r}
# Definimos nuestros parámetros
millas <-  18
cilindros <- 6
mi_df_query <- dbGetQuery(conn,
                     'SELECT car_names, mpg, cyl FROM cars_data WHERE mpg >= ? AND cyl >= ?',
                     params = c(millas, cilindros))
mi_df_query
```

+ Aquí usamos el símbolo `?` en la sintaxis SQL para decirle que le estoy insertando parámetros en la sentencia `params`

+ Finalmente, nos vamos a desconectar de esta base de datos

```{r}
dbDisconnect(conn)
```

## Otro ejemplo: Tabla de baseball

```{r}
lahman_s <- dbplyr::lahman_sqlite()
bateo <- tbl(lahman_s, "Batting")
```

```{r}
bateo |> class()
```


```{r}
bateo %>% show_query()
```

```{r}
bateo |> dplyr::filter(playerID == "mcguide01")
```


```{r}
bateo |> dplyr::filter(playerID == "mcguide01") |> show_query()
```

```{r}
bateo |> dplyr::filter(playerID == "mcguide01") |>
  dplyr::select(yearID,R) |>
  show_query()
```
```{r}
bateo |> dplyr::filter(playerID == "mcguide01") |>
  mutate(era = if_else(yearID <= 1888, "vieja era", "nueva era")) |>
  dplyr::select(playerID, yearID, era, teamID) |>
  show_query()
```


```{r}
con <- dbConnect(RSQLite::SQLite(), dbname = "titanic.db")
```


```{r}
dbListTables(con)
```

```{r}
primer_query <- dbGetQuery(con, "SELECT * FROM titanic")
primer_query
```

```{r}
primer_query |> class()
```

```{r}
#install.packages("readxl")
library(readxl) # Para leer archivos de Excel
library(dplyr)
library(ggplot2)
library(lubridate) # Sirve para manejar algunas variables de fecha
```

+ Empecemos cargando de nuevo dataset del archivo "VentasNum2024.xlsx"

```{r}
datos_ventas <- readxl::read_xlsx("VentasNum2024.xlsx", sheet = "Ventas")
```

```{r}
datos_ventas |> head()
```


```{r}
names(datos_ventas)
```

```{r}
library(janitor)
```


```{r}
datos_ventas |> clean_names()
```

```{r}
datos_ventas <- datos_ventas |> clean_names()
```


```{r}
head(datos_ventas)
```

Para casos en los que se tiene un conjunto de archivos de datos que parecen idénticos 

Pero hacemos dplyr::bind_rows() o rbind() y fallan, ya sea porque las columnas son diferentes o porque las clases de las columnas no coinciden entre los dataframes

compare_df_cols() toma los nombres sin comillas de data.frames / tibbles, o una lista de data.frames, y devuelve un resumen de cómo se comparan.

Es decir, observa cuáles son los tipos de columnas, cuáles faltan o están presentes en las diferentes entradas, y cómo difieren los tipos de columnas.


```{r}
df1 <- data.frame(a = 1:2, b = c("grande", "pequeño"))
df2 <- data.frame(a = 10:12, b = c("mediano", "pequeño", "grande"), c = 0,
                  stringsAsFactors = TRUE)
df3 <- df1 |> dplyr::mutate(b = as.character(b))
```

```{r}
df1
```

```{r}
df2
```

```{r}
df3
```
```{r}
compare_df_cols(df1, df2, df3)
```

```{r}
compare_df_cols(df1, df2, df3, return = "mismatch")
```

```{r}
compare_df_cols(df1, df2, df3, return = "mismatch",
                bind_method = "rbind")
```
compare_df_cols_same() devuelve TRUE o FALSE indicando si los dataframes efectivamente se pueden unir por filas con el método de unión especificado.


```{r}
compare_df_cols_same(df1, df3)
```

```{r}
compare_df_cols_same(df2, df3)
```


```{r}
mtcars %>%
  tabyl(gear, cyl)
```

```{r}
mtcars %>%
  tabyl(gear, cyl, am)
```

```{r}
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col")
```

```{r}
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col") %>%
  adorn_percentages("row")
```

```{r}
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col") %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2)
```

```{r}
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col") %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns()
```

```{r}
mtcars %>%
  tabyl(gear, cyl) %>%
  adorn_totals("col") %>%
  adorn_percentages("row") %>%
  adorn_pct_formatting(digits = 2) %>%
  adorn_ns() %>%
  adorn_title()
```

```{r}
get_dupes(mtcars, wt, cyl)
```

```{r}
get_dupes(datos_ventas, id_venta)
```


get_one_to_one(): Esta función muestra que columnas (si es que las hay)
tienen relaciones uno a uno entre sí.

```{r}
library(dplyr)
```

```{r}
starwars
```

```{r}
datos <- dplyr::starwars
```

```{r}
datos[1:10,]
```


```{r}
datos[1:10,] %>%
  get_one_to_one()
```


```{r}
datos[1:5,] %>%
  get_one_to_one()
```

```{r}
datos[1:5,]
```

```{r}
data_superstore <- read_csv("Sample - Superstore.csv")
```

```{r}
head(data_superstore)
```

```{r}
data_superstore |> get_one_to_one()
```

```{r}
mi_dataframe <- data.frame(v1 = c(1, NA, 3),
                           v2 = c(NA, NA, NA),
                           v3 = c("a", NA, "b"))

mi_dataframe
```

```{r}
mi_dataframe |> remove_empty(c("rows", "cols"))
```
```{r}
mi_dataframe <- data.frame(estudiantes = c("Felipe", "Verónica", "Alina"),
                           calificaciones = 8:10,
                           curso = "Matemáticas")

mi_dataframe
```

```{r}
mi_dataframe |> remove_constant()
```


```{r}
df_que_me_pasaron <- data.frame(X_1 = c(NA, "ID", 1:3),
                                X_2 = c(NA, "Value", 4:6))

df_que_me_pasaron
```

```{r}
row_to_names(df_que_me_pasaron, row_number = 2)
```

```{r}
df_que_me_pasaron <- data.frame(X_1 = c(NA, NA, NA, "ID", 1:3),
                                X_2 = c(NA, NA, NA, "Value", 4:6))

df_que_me_pasaron
```

```{r}
row_to_names(df_que_me_pasaron, row_number = 4)
```


## De EXCEL y sus infiernos con las fechas

Algunas veces se cargan datos desde Excel y se ve un valor como 42223 donde debería haber una fecha... ¿Qué hacemos?

Primero recuperarnos del micro-infarto

Luego usamos la función excel_numeric_to_date()

Esta función convierte esos números (seriales) a la clase Date

Tiene opciones para diferentes sistemas de codificación de fechas de Excel, preservando fracciones de una fecha como hora (en cuyo caso el valor devuelto es de clase POSIXlt) y especificando una zona horaria.

```{r}
excel_numeric_to_date(41103)
```

```{r}
excel_numeric_to_date(41103.01) # ignora los puntos decimales
```

```{r}
excel_numeric_to_date(41103.01, include_time = TRUE) # regresa un objeti POSIXlt
```

```{r}
excel_numeric_to_date(41103.01, date_system = "mac pre-2011")
```

Las nuevas funciones convert_to_date() y convert_to_datetime() son más robustas ante una mezcla de tipos de entrada.

Particularmente útiles cuando se leen muchas excels que deberían tener los mismos formatos de columna, pero no los tienen.

```{r}
convert_to_date(c("2020-02-29", "40000.1"))
```

```{r}
convert_to_date(c("2020-02-29", "40000.1", "26-04-2021"))
```


```{r}
convert_to_date(c("2020-02-29", "40000.1", "04-26-2021"))
```

```{r}
convert_to_date(c("2020-02-29", "40000.1", "2021/04/26"))
```

```{r}
mi_vector <- c("strongly agree", "agree", "neutral", "neutral", "disagree", "strongly agree", "agree", "neutral", "neutral")

mi_vector
```

```{r}
factor(mi_vector,
       levels = c("strongly agree", "agree", "neutral", "disagree", "strongly disagree"))
```

```{r}
mi_vector <- factor(mi_vector,
                    levels = c("strongly agree", "agree", "neutral", "disagree", "strongly disagree"))
```

```{r}
top_levels(mi_vector)
```

```{r}
top_levels(mi_vector, n = 1)
```

```{r}
top_levels(mi_vector, n = 2)
```
