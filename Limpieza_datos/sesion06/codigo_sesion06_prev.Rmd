---
title: "Sesión 05"
output: html_document
date: "2025-03-11"
---

```{r}
library(tidyr)
library(ggplot2)
library(stringr)
library(quanteda)
library(quanteda.textplots)
```

+ Veamos otro ejemplo

```{r}
datos <- tidyr::billboard
```

```{r}
datos |> head()
```

+ Este dataset lo quiero convertir de ancho a largo

```{r}
datos |> tidyr::pivot_longer(
  cols = starts_with("wk"),
  names_to = "week",
  values_to = "rank",
  values_drop_na = TRUE)
```

+ Me sigue estorbando la wk de la columna week. Vamos a quitarselo

```{r}
datos |> tidyr::pivot_longer(
  cols = starts_with("wk"),
  names_to = "week",
  names_prefix = "wk", # Le agregué esta línea
  values_to = "rank",
  values_drop_na = TRUE)
```

+ Voy a guardar este dataset

```{r}
datos_largos <- datos |> tidyr::pivot_longer(
  cols = starts_with("wk"),
  names_to = "week",
  names_prefix = "wk",
  values_to = "rank",
  values_drop_na = TRUE)
```

```{r}
library(dplyr)
```
+ Convierto la columna week en numerica la estaba trabajando con string, con nuestra aniga la funcion mutate

```{r}
datos_largos <- datos_largos |> dplyr::mutate(week = as.numeric(week))
```


```{r}
head(datos_largos)
```




+ Vamos a encontrar cuantas semana estuvieron en el top 100 de billboard y en esas semanas, cual fue su mejor y peor posicion


```{r}
datos_resumen <- datos_largos |> dplyr::group_by(artist, track, date.entered) |>
  summarise(max_sem = max(week), min_ranking = min(rank), max_ranking = max(rank))
```


```{r}
head(datos_resumen)
```





```{r}
datos_resumen <- datos_resumen |> ungroup()
```


```{r}
head(datos_resumen)
```

+ Como tengo canciones de 1999 y 2000, me gustsartia extraer el dia

```{r}
datos_resumen <- datos_resumen |> mutate(dia_anio = lubridate::yday(date.entered))
```

```{r}
datos_resumen
```


+ Veamos las canciones previa al 2000 


```{r}
datos_resumen |> dplyr::filter(date.entered <= "1999-12-31") |> ggplot() +
  geom_bar(aes(x = reorder(track, -dia_anio), y = max_sem), stat = "identity") +
  coord_flip()
```


#Grafica donde le agregamos la etiqueta del artista a cada grafica

```{r}
datos_resumen |> 
  dplyr::filter(date.entered > "1999-12-31", date.entered <= "2000-02-28") |> 
  ggplot() +
  geom_bar(aes(x = reorder(track, -dia_anio), y = max_sem),
           stat = "identity", fill = "lightblue") +
  geom_text(aes(x = track, y = max_sem, label = artist), size = 3) +
  coord_flip() +
  theme_light()
```

Haciendo un filtro por fecha a nuestros datos


```{r}
datos_resumen |> 
  dplyr::filter(date.entered > "2000-10-30", date.entered <= "2000-12-31") |> 
  ggplot() +
  geom_bar(aes(x = reorder(track, -dia_anio), y = max_sem),
           stat = "identity", fill = "lightblue") +
  geom_text(aes(x = track, y = max_sem, label = artist), size = 3) +
  coord_flip() +
  theme_light()
```

```{r}
datos_resumen |> 
  dplyr::filter(date.entered >= "2000-07-01", date.entered <= "2000-08-31") |> 
  ggplot() +
  geom_bar(aes(x = reorder(track, -dia_anio), y = max_sem),
           stat = "identity", fill = "lightblue") +
  geom_text(aes(x = track, y = max_sem, label = artist), size = 3) +
  coord_flip() +
  theme_light()
```
¿Cuales fueron las canciones que estuvieron mas semanañas en el top100?

```{r}
quantile(datos_resumen$max_sem, probs = c(0.8, 0.9, 1))
```

Graficarelos el punto de corte como 25, ie el mejor 90%

```{r}
datos_resumen |> dplyr::filter(max_sem >= 25) |>
  dplyr::filter(date.entered <= "1999-12-31") |> 
  ggplot() +
  geom_bar(aes(x = reorder(track, -dia_anio), y = max_sem),
           stat = "identity", fill = "lightblue") +
  geom_text(aes(x = track, y = max_sem, label = artist), size = 3) +
  coord_flip() +
  theme_light()
```

Top mas popular pero ahora del año 2000

```{r}
datos_resumen |> dplyr::filter(max_sem >= 25) |> #Aqui indicamos el 90% de nuestra muestra, lo sacamos con los cuantiles el mejor 10%
  dplyr::filter(date.entered > "1999-12-31") |> 
  ggplot() +
  geom_bar(aes(x = reorder(track, -dia_anio), y = max_sem),
           stat = "identity", fill = "lightblue") +
  geom_text(aes(x = track, y = max_sem, label = artist), size = 3) +
  coord_flip() +
  theme_light()
```

## Lyrics

vamos a usar el dataset, de lyrics de la libreria billboard



```{r}
datos <- billboard::lyrics
datos |> head()
```

```{r}
datos |> mutate(year = as.numeric(year)) |> dplyr::filter(year >= 2010)
```
Tambien verte si puedo identificar algo de los datos de spotify



```{r}
billboard::spotify_track_data |> mutate(year = as.numeric(year)) |> dplyr::filter(year >= 2010)
```


busquemos a lil peep

```{r}
billboard::spotify_track_data |> filter(artist_name %in% c("Lil peep", "lil peep", "Eminem") )
```


 ### Tarea, elegir una cancion para que el final analiceos la letra

libreria buena para limpiarla :0000


```{r}
who
```


```{r}
who %>% pivot_longer(
  cols = new_sp_m014:newrel_f65,
  names_to = c("diagnosis", "gender", "age"),
  names_pattern = "new_?(.*)_(.)(.*)",
  values_to = "count"
)
```

+ Mas adelante veremos como seguir limpianzo la columan age

```{r}
anscombe
```

```{r}
datos_anscombe <- anscombe %>%
  pivot_longer(
    everything(),
    names_pattern = "(.)(.)",
    names_to = c(".value", "set")
    
  )
```

Pauete basico de estadistica, donde tiene misma dedidas estadisticas

```{r}
datos_anscombe
```

vamos a graficar estas parejas por grupos


```{r}
datos_anscombe |> ggplot() +
  geom_point(aes(x = x, y = y, color = set)) +
  facet_wrap(~set) +
  theme_light()
```

```{r}
datos_anscombe |> dplyr::group_by(set) |> summarise(x_media = mean(x), y_media = mean(y), x_var = var(x), y_var = var(y), covarianza = cov(x,y))
```

```{r}
#corrplot::corrplot(datos_anscombe)
```


+ Este cuarteto tiene una utilidas mas didactic a que practica, ya que la regresion lineal no es todo

```{r}
datos_ventas <- data.frame(
  producto = c("A", "A", "B", "B", "B", "C", "C"),
  region = c("Norte", "Sur", "Norte", "Este", "Sur", "Norte", "Sur"),
  enero = c(500, NA, 600, NA, 580, 300, 350),
  febrero = c(450, 490, NA, 260, 700, 320, 400)
)

datos_ventas
```



```{r}
df <- data.frame(estudiante = rep(c('Ariana', 'Daniel'), each=4),
                 anio = rep(c(1, 1, 2, 2), times=2),
                 semestre = rep(c('primavera', 'otonio'), times=4),
                 calif =c(84, 60, 78, 77, 62, 99, 88, 74))

df
```

Vamos a convertir de una tabla ancha a una tabla ancha 


```{r}
df |> tidyr::pivot_wider(names_from = semestre, values_from = calif)
```

Veamos un ultimo ejemplo


```{r}
df <- data.frame(
  anio = rep(2024:2025, each = 12),
  mes = rep(month.name, times = 2))

df
```

Le agregare una columna que representara alguna medicion que no interese, de forma aleatoria


```{r}
set.seed(06032025)

df <- df |> mutate(medicion = 100*runif(n()))
```

```{r}
df
```

Dew nuevo, convirtiendo desta tabla larga a una ancha

```{r}
df |> pivot_wider(names_from = "mes", values_from = "medicion")
```

 ## Ejemplitos de tarea, es lo mismo que arribapara que los corramos nosotros

```{r}
fish_encounters
```


```{r}
fish_encounters %>%
  pivot_wider(names_from = station, values_from = seen)
```

```{r}
fish_encounters %>%
  pivot_wider(names_from = station, values_from = seen, values_fill = 0)
```

```{r}
us_rent_income
```


```{r}
us_rent_income %>%
  pivot_wider(
    names_from = variable,
    values_from = c(estimate, moe))
```


## -----------------------------------------------------------------


```{r}
df <- data.frame(estudiante = c('Berenice', 'Berenice', 'Leo', 'Leo', 'Frida', 'Frida'),
                 anio = c(2024, 2025, 2024, 2025, 2024, 2025),
                 puntos = c(22, 29, 18, 11, 12, 19),
                 retardos = c(2, 3, 6, 8, 5, 2))

df
```


 vamos a hacer una mala practica en datos que no se debe hacer pero que es muy comun en el manejo de datos, vamos a pegar los valores de varias columnas 
 
 se hace con la funcion unite
```{r}
df |> tidyr::unite(c('puntos', 'retardos'), col = 'puntos_y_retardos', sep='-')
```

vamos agregar una columna de reportes  a este dataframe 

```{r}
df <- df |> mutate(reportes = c(2, 3, 3, 2, 1, 0))

df
```



haciendo otra cochinad aun mas grande

```{r}
df |> tidyr::unite(c('puntos', 'retardos', 'reportes'), col='mounstrosa', sep='/')
```

Asi como puedo "pegar", los valores de las columnas, tambien puedo separarlas y en mi opicion es mas util y mas comun 

en la celda viene lalo/hombre/vegetariano y yo lo quiero separar en 3 columnas

- tambien puedo importar informacion csv de una url


```{r}
url <- "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-25/details.csv"
datos <- readr::read_csv(url)
```

+   Veamos un poquito de este dataset 

```{r}
datos |> head()
```

```{r}
datos |> select(id, primary, boardgamecategory)
```

Podemos ver que hay juegos con multiples categorias

```{r}
datos <- datos |> select(id, primary, boardgamecategory)
```

```{r}
datos |> head()
```
 + le dijo donde quiero ahcer la separacion de palabas

```{r}
datos |> separate_longer_delim(cols = boardgamecategory, delim = ", ")
```

Sifue sin gustamer la columna boardercategory, ya que la columna no esta limpia, todavia tiene caracteres feos

```{r}
library(stringr) #Libreria para hacer limpieza de datos 
```

```{r}
patron <- c(`[` = "", `]` = "", `"` = "", `'` = "") |> coll()
```

```{r}
datos |> separate_longer_delim(cols = boardgamecategory, delim = ", ") |>
  dplyr::mutate(boardgamecategory_limpio =  #Creo que nueva coluna, donde los patrones de arriba los sustituya po nada
           stringr::str_replace_all(boardgamecategory, pattern = patron)
         )
```

Por supuesto tambien podemos pasarlo de semilargo a largo 

```{r}
datos <- data.frame(anio = c(2024, 2024, 2025),
                    inventario = c("vanilla,1.30", "chocolate,1.50", "fresa,1.00"))

datos
```

vamos a limpiar esta tabla

```{r}
datos |> separate_wider_delim(cols = inventario, delim = ",",
                              names = c("sabor", "precio")
  )
```

```{r}
df <- data.frame(x1 = c("A", "B", "C", "D", "E", "F"),
                 x2 = c(1, NA, NA, 4, NA, 7))

df
```

```{r}
df |> tidyr::drop_na(x2)
```
```{r}
df |> tidyr::fill(x2)
```


```{r}
df |> tidyr::fill(x2, .direction = "up")
```


```{r}
df |> replace_na(replace = list(x2 = pi))
```

```{r}
starwars |> head()
```



```{r}
starwars |> dplyr::select(name, films)
```

```{r}
sub_datos <- starwars |> head(n = 15)
```


```{r}
sub_datos$films
```



```{r}
sub_datos |> dplyr::select(name, films) |>
  tidyr::unnest_longer(films)
```

```{r}
sub_datos |> dplyr::select(name, films) |>
  tidyr::unnest_wider(films, names_sep = "_")
```

```{r}
sub_datos |> dplyr::select(name, films) |>
  tidyr::hoist(films, primera = 1, segunda = 2)
```

```{r}
sub_datos
```

```{r}
starwars |>
  dplyr::rowwise() |>
  mutate(num_transportes = length(c(vehicles, starships)))
```


```{r}
sub_datos |>
  dplyr::rowwise() |>
  mutate(transporte = list(append(vehicles, starships))) |>
  tidyr::unnest_longer(transporte) #|> dplyr::select(name, transporte)
```

## Introducción a la limpieza de texto

```{r}
mi_string <- "Ejemplo de STRING, con caraceteres varios (12, 15 y 10.2)?!"

mi_string
```

```{r}
(string_en_minuscula <- tolower(mi_string))
```

```{r}
otro_string <- "Wow, tengo más que decir!!"
paste(mi_string, otro_string, sep = " ")
```

```{r}
paste(mi_string, otro_string, sep = "@@@@")
```

```{r}
paste(mi_string, otro_string)
```

```{r}
paste0(mi_string, otro_string)
```

```{r}
mi_string <- "Ejemplo de STRING,      con caraceteres varios (12, 15 y 10.2)?!"

mi_string
```

```{r}
stringr::str_split(string = mi_string, pattern = " ")
```

```{r}
stringr::str_split(string = mi_string, pattern = boundary("word"))
```


```{r}
stringr::str_count(string = mi_string, pattern = " ")
```

```{r}
stringr::str_count(string = mi_string, pattern = boundary("word"))
```

```{r}
fruits <- c(
  "apples and oranges and pears and bananas",
  "pineapples and mangos and guavas"
)
```

```{r}
fruits |> stringr::str_split(pattern = " and ")
```


```{r}
fruits |> stringr::str_split(pattern = " and ", simplify = TRUE)
```

```{r}
fruits |> stringr::str_split(pattern = " and ", n = 3)
```

```{r}
fruits |> stringr::str_split(pattern = " and ", n = 2)
```

```{r}
fruits |> stringr::str_split(pattern = " and ", n = 5)
```

```{r}
fruits |> stringr::str_split_fixed(pattern = " and ", n = 3)
```

```{r}
fruits |> stringr::str_split_fixed(pattern =" and ", n = 5)
```

```{r}
fruits |> stringr::str_split_i(pattern = " and ", i = 1)
```

```{r}
fruits |> stringr::str_split_i(pattern = " and ", i = 4)
```

```{r}
fruits |> stringr::str_split_i(pattern = " and ", i = 2)
```

```{r}
fruits |> stringr::str_split_i(pattern = " and ", i = -1)
```

```{r}
fruits |> stringr::str_split_i(pattern = " and ", i = -2)
```


```{r}
infierno_de_i <- c("istanbul", "İzmar", "Istanbul", "izmar", "\u0130")
infierno_de_i
```
```{r}
stringr::str_detect(infierno_de_i, pattern = coll("i", TRUE))
```

coll: Función se utiliza para "collation" (algo así como cotejo o compaginación), que es una forma de comparar strings teniendo en cuenta reglas específicas de la configuración regional (por ejemplo, sensibilidad a mayúsculas y minúsculas, orden de caracteres, etc.).

TRUE: Este argumento especifica que la búsqueda debe ser sensible a mayúsculas y minúsculas. Si fuera FALSE, la búsqueda sería insensible a mayúsculas y minúsculas.

```{r}
stringr::str_detect(infierno_de_i, coll("i", TRUE, locale = "tr"))
```

locale = "tr", especifica la configuración regional que se utilizará para la collation. La configuración regional "tr" se refiere al turco. En turco, la letra "i" tiene un comportamiento especial en cuanto a la sensibilidad a mayúsculas y minúsculas (por ejemplo, la versión en mayúscula de "i" es "İ", y la versión en minúscula de "I" es "ı").

```{r}
stringr::str_detect(infierno_de_i, fixed("i", TRUE))
```

Con fixed se especifica que el patrón debe tratarse como un string fijo (i.e. no como una expresión regular). Esto significa que los caracteres especiales en el patrón se interpretan literalmente, no como metacaracteres de regex.

```{r}
mi_string
```

```{r}
str_split(mi_string, pattern = "!")
```

```{r}
str_split(mi_string, pattern = "!")[[1]]
```

```{r}
mi_string_en_vector <- str_split(mi_string, pattern = "!")[[1]]
```


```{r}
grep(pattern = "\\?", x = mi_string_en_vector)
```

```{r}
stringr::str_replace_all(mi_string, "e","@@")
```

```{r}
stringr::str_extract_all(mi_string,"[0-9]+")
```
```{r}
stringr::str_extract_all(mi_string,"[?]+")
```


```{r}
str_extract_all(mi_string, "[a-z]+")
```

```{r}
str_extract_all(mi_string, regex("[a-z]+", TRUE))
```



```{r}
mi_vector <- c("123 grapes", "apples x4", "bag of flour",
               "kiwi and lime", "Bag of sugar", "milk x2")
```

```{r}
str_extract(mi_vector, "\\d")
```

```{r}
str_extract_all(mi_vector, "\\d")
```

```{r}
str_extract(mi_vector, "[a-z]+")
```

```{r}
str_extract(mi_vector, "[a-z]{1,4}")
```

```{r}
str_extract(mi_vector, "[a-z]{1,3}")
```

```{r}
str_extract(mi_vector, "[a-z]{1,8}")
```

```{r}
str_extract(mi_vector, "\\b[a-z]+\\b")
```

Es un boundary (más en específico, un word boundary); hace que el match ocurra al inicio o al final de una palabra

```{r}
str_extract(mi_vector, "\\b[a-z]+")
```

```{r}
str_extract(mi_vector, "[a-z]+\\b")
```

```{r}
str_extract(mi_vector, regex("[a-z]+\\b", TRUE))
```

```{r}
str_extract(mi_vector, "([a-z]+) of ([a-z]+)")
```

```{r}
str_extract(mi_vector, "([a-z]+) of ([a-z]+)", group = 1)
```

```{r}
str_extract(mi_vector, "([a-z]+) of ([a-z]+)", group = 2)
```


```{r}
mi_texto <- read.delim("ObamaSpeech.txt", header = FALSE)
```

```{r}
mi_texto |> str()
```

```{r}
mi_texto[1,1] |> corpus() |> summary()
```

```{r}
mi_texto[1,1] |> quanteda::tokens() |>
    dfm()
```

```{r}
mi_texto[17,1]
```

```{r}
head(stopwords("en"), 20)
```

```{r}
head(stopwords("ru"), 10)
```

```{r}
head(stopwords("it"), 10)
```

```{r}
head(stopwords("es"), 10)
```


```{r}
mi_texto[17,1] |> quanteda::tokens() |> 
  tokens_remove(stopwords("en")) |>
  dfm()
```


```{r}
primera_frase <- "This is $10 in 999 different ways,\n up and down; left and right!"
segunda_frase <- "@koheiw7 working: on #quanteda 2day\t4ever, http://textasdata.com?page=123."
```


```{r}
texto_completo <- c(text1 = primera_frase,
                    text2 = segunda_frase,
                    text3 = mi_texto[17,1],
                    text4 = mi_texto[27,1],
                    text5 = mi_texto[37,1],
                    text6 = mi_texto[47,1],
                    text7 = mi_texto[57,1],
                    text8 = billboard::lyrics[5,"lyrics"])
```

```{r}
texto_completo |> quanteda::tokens()
```


```{r}
texto_completo |> quanteda::tokens () |>
  tokens_remove(stopwords("en")) |>
  dfm() |> textplot_wordcloud(min_count = 2)
```

```{r}
texto_completo |> quanteda::tokens(remove_numbers = TRUE,
                                   remove_punct = TRUE,
                                   remove_separators = TRUE) |>
  dfm() |> textplot_wordcloud()
```

```{r}
texto_completo |> quanteda::tokens(remove_numbers = TRUE,
                                   remove_punct = TRUE,
                                   remove_separators = TRUE) |>
  tokens_remove(stopwords("en")) |>
  dfm() |> textplot_wordcloud()
```
